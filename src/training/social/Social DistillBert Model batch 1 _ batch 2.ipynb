{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ktrain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ktrain import text\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"/Users/gbaldonado/Developer/ml-alma-taccti/ml-alma-taccti/data/for_training/merged/Social_plus_batch_1_batch_2_merged.xlsx\"\n",
    "social_df = pd.read_excel(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "social Train: 3043, Test: 859, Total: 3902\n",
      "ðŸ“Š social Dataset Train-Test Split Results:\n",
      "âœ… Train: 3043 samples (Positives: 685, 22.51%)\n",
      "âœ… Test: 859 samples (Positives: 193, 22.47%)\n",
      "ðŸ”¹ Total Dataset: 3902 samples\n",
      "âœ… social train and test sets successfully created and saved!\n"
     ]
    }
   ],
   "source": [
    "# Perform train-test split (keeping stratification)\n",
    "train_social, test_social = train_test_split(\n",
    "    social_df, test_size=0.22, random_state=42, stratify=social_df[\"label\"]\n",
    ")\n",
    "\n",
    "# Verify counts\n",
    "print(f\"social Train: {len(train_social)}, Test: {len(test_social)}, Total: {len(social_df)}\")\n",
    "\n",
    "# Count total samples\n",
    "total_train = len(train_social)\n",
    "total_test = len(test_social)\n",
    "\n",
    "# Count positive (Class 1) samples\n",
    "train_positives = train_social[\"label\"].sum()\n",
    "test_positives = test_social[\"label\"].sum()\n",
    "\n",
    "# Calculate percentages\n",
    "train_positive_pct = (train_positives / total_train) * 100\n",
    "test_positive_pct = (test_positives / total_test) * 100\n",
    "\n",
    "# Print results\n",
    "print(f\"ðŸ“Š social Dataset Train-Test Split Results:\")\n",
    "print(f\"âœ… Train: {total_train} samples (Positives: {train_positives}, {train_positive_pct:.2f}%)\")\n",
    "print(f\"âœ… Test: {total_test} samples (Positives: {test_positives}, {test_positive_pct:.2f}%)\")\n",
    "print(f\"ðŸ”¹ Total Dataset: {len(social_df)} samples\")\n",
    "\n",
    "\n",
    "# Define save directory\n",
    "save_dir = \"/Users/gbaldonado/Developer/ml-alma-taccti/ml-alma-taccti/data/for_training/merged/soc_train_test\"\n",
    "os.makedirs(save_dir, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "# Save train and test sets\n",
    "train_social.to_excel(f\"{save_dir}/train_social.xlsx\", index=False)\n",
    "test_social.to_excel(f\"{save_dir}/test_social.xlsx\", index=False)\n",
    "\n",
    "print(\"âœ… social train and test sets successfully created and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_social['sentence']\n",
    "y = train_social['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 18, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da77262de8c94fc198977123f2205b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e3e39467c064a97b7511057dbf45850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/736M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 21\n",
      "\t95percentile : 40\n",
      "\t99percentile : 56\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb51482d5694c9792f0d34f6cd43f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01d487057a746fc88777fed7fc64795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gbaldonado/miniforge3/envs/ml_env/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:562: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 20\n",
      "\t95percentile : 37\n",
      "\t99percentile : 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define model name\n",
    "model_name = 'microsoft/deberta-v3-base'  # You can also use 'microsoft/deberta-v3-small' for a smaller model\n",
    "\n",
    "# Initialize DeBERTa transformer\n",
    "deberta_transformer = text.Transformer(model_name, maxlen=MAXLEN, class_names=[0, 1])\n",
    "\n",
    "# Preprocess training and validation sets\n",
    "training_set = deberta_transformer.preprocess_train(X_train.tolist(), y_train.tolist())\n",
    "validation_set = deberta_transformer.preprocess_test(X_test.tolist(), y_test.tolist())\n",
    "\n",
    "# Get DeBERTa classifier model\n",
    "deberta_base_model = deberta_transformer.get_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "deberta_learner = ktrain.get_learner(deberta_base_model, train_data=training_set, val_data=validation_set, batch_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using triangular learning rate policy with max lr of 2e-05...\n",
      "Epoch 1/5\n",
      "406/406 [==============================] - 1130s 3s/step - loss: 0.5483 - accuracy: 0.7494 - val_loss: 0.5116 - val_accuracy: 0.7750\n",
      "Epoch 2/5\n",
      "406/406 [==============================] - 950s 2s/step - loss: 0.3999 - accuracy: 0.8357 - val_loss: 0.3103 - val_accuracy: 0.8719\n",
      "Epoch 3/5\n",
      "406/406 [==============================] - 915s 2s/step - loss: 0.2856 - accuracy: 0.8850 - val_loss: 0.3027 - val_accuracy: 0.8818\n",
      "Epoch 4/5\n",
      "406/406 [==============================] - 969s 2s/step - loss: 0.2656 - accuracy: 0.8998 - val_loss: 0.3027 - val_accuracy: 0.8736\n",
      "Epoch 5/5\n",
      "406/406 [==============================] - 918s 2s/step - loss: 0.2170 - accuracy: 0.9154 - val_loss: 0.3494 - val_accuracy: 0.8686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x3ea8a6850>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deberta_learner.autofit(2e-5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 18s 884ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91       472\n",
      "           1       0.68      0.80      0.73       137\n",
      "\n",
      "    accuracy                           0.87       609\n",
      "   macro avg       0.81      0.84      0.82       609\n",
      "weighted avg       0.88      0.87      0.87       609\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[420,  52],\n",
       "       [ 28, 109]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deberta_learner.validate(class_names=deberta_transformer.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_deberta_v2_for_sequence_classification_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " deberta (TFDebertaV2MainLa  multiple                  183831552 \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " pooler (TFDebertaV2Context  multiple                  590592    \n",
      " Pooler)                                                         \n",
      "                                                                 \n",
      " cls_dropout (TFDebertaV2St  multiple                  0         \n",
      " ableDropout)                                                    \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 184423682 (703.52 MB)\n",
      "Trainable params: 184423682 (703.52 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deberta_learner.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "deberta_predictor = ktrain.get_predictor(deberta_learner.model, preproc=deberta_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "deberta_test_data = test_social['sentence'].tolist()\n",
    "deberta_test_label = test_social['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_deberta = deberta_predictor.predict(deberta_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_deberta = [int(x) for x in y_pred_deberta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative: 600, False Positive: 66, False Negative: 50, True Positive: 143\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(deberta_test_label, y_pred_deberta).ravel()\n",
    "print('True Negative: {}, False Positive: {}, False Negative: {}, True Positive: {}'.format(tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       666\n",
      "           1       0.68      0.74      0.71       193\n",
      "\n",
      "    accuracy                           0.86       859\n",
      "   macro avg       0.80      0.82      0.81       859\n",
      "weighted avg       0.87      0.86      0.87       859\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('  Classification Report:\\n',classification_report(deberta_test_label,y_pred_deberta),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95       117\n",
      "           1       0.72      0.92      0.81        25\n",
      "\n",
      "    accuracy                           0.92       142\n",
      "   macro avg       0.85      0.92      0.88       142\n",
      "weighted avg       0.94      0.92      0.93       142\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('  Classification Report:\\n',classification_report(deberta_test_label,y_pred_deberta),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deberta_predictor.save('./model/distilbert_base_uncased_model') # 256 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC roc score for deberta model:  0.8209167716939738\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC roc score for deberta model: \", roc_auc_score(deberta_test_label,y_pred_deberta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
