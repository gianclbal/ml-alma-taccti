{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ktrain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>phrase</th>\n",
       "      <th>batch</th>\n",
       "      <th>original_label</th>\n",
       "      <th>changed?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>why am i here?</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"ever since i was little i wanted to be a doc...</td>\n",
       "      <td>batch_1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>well why does anyone pursue a higher education?</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"ever since i was little i wanted to be a doc...</td>\n",
       "      <td>batch_1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to better one self and be able to succeed late...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"ever since i was little i wanted to be a doc...</td>\n",
       "      <td>batch_1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ever since i was little i wanted to be a docto...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"ever since i was little i wanted to be a doc...</td>\n",
       "      <td>batch_1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i always wanted to be able to help people and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"ever since i was little i wanted to be a doc...</td>\n",
       "      <td>batch_1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8715</th>\n",
       "      <td>anyways, the path im referring to is basically...</td>\n",
       "      <td>0</td>\n",
       "      <td>['one of these goals is being in a career i en...</td>\n",
       "      <td>batch_2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8716</th>\n",
       "      <td>i know that i want a career in which ill help ...</td>\n",
       "      <td>0</td>\n",
       "      <td>['one of these goals is being in a career i en...</td>\n",
       "      <td>batch_2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8717</th>\n",
       "      <td>in any case, i intend to keep moving forward i...</td>\n",
       "      <td>0</td>\n",
       "      <td>['one of these goals is being in a career i en...</td>\n",
       "      <td>batch_2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8718</th>\n",
       "      <td>i am here to fulfill a covenant with myself an...</td>\n",
       "      <td>1</td>\n",
       "      <td>['i am here to fulfill a covenant with myself ...</td>\n",
       "      <td>batch_2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8719</th>\n",
       "      <td>i am here to be a learned person.i am here to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>['i am here to fulfill a covenant with myself ...</td>\n",
       "      <td>batch_2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8720 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label  \\\n",
       "0                                        why am i here?      0   \n",
       "1       well why does anyone pursue a higher education?      0   \n",
       "2     to better one self and be able to succeed late...      1   \n",
       "3     ever since i was little i wanted to be a docto...      1   \n",
       "4     i always wanted to be able to help people and ...      1   \n",
       "...                                                 ...    ...   \n",
       "8715  anyways, the path im referring to is basically...      0   \n",
       "8716  i know that i want a career in which ill help ...      0   \n",
       "8717  in any case, i intend to keep moving forward i...      0   \n",
       "8718  i am here to fulfill a covenant with myself an...      1   \n",
       "8719  i am here to be a learned person.i am here to ...      1   \n",
       "\n",
       "                                                 phrase    batch  \\\n",
       "0     [\"ever since i was little i wanted to be a doc...  batch_1   \n",
       "1     [\"ever since i was little i wanted to be a doc...  batch_1   \n",
       "2     [\"ever since i was little i wanted to be a doc...  batch_1   \n",
       "3     [\"ever since i was little i wanted to be a doc...  batch_1   \n",
       "4     [\"ever since i was little i wanted to be a doc...  batch_1   \n",
       "...                                                 ...      ...   \n",
       "8715  ['one of these goals is being in a career i en...  batch_2   \n",
       "8716  ['one of these goals is being in a career i en...  batch_2   \n",
       "8717  ['one of these goals is being in a career i en...  batch_2   \n",
       "8718  ['i am here to fulfill a covenant with myself ...  batch_2   \n",
       "8719  ['i am here to fulfill a covenant with myself ...  batch_2   \n",
       "\n",
       "      original_label  changed?  \n",
       "0                  0     False  \n",
       "1                  0     False  \n",
       "2                  1     False  \n",
       "3                  1     False  \n",
       "4                  1     False  \n",
       "...              ...       ...  \n",
       "8715               0     False  \n",
       "8716               0     False  \n",
       "8717               0     False  \n",
       "8718               1     False  \n",
       "8719               1     False  \n",
       "\n",
       "[8720 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspirational_df = pd.read_excel('/Users/gbaldonado/Developer/ml-alma-taccti/ml-alma-taccti/src/data_preprocessing/prepare_sentence_level/aspirational_plus_batch_1_batch_2_merged.xlsx')\n",
    "aspirational_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 Train: 2727, Test: 770, Total: 3497\n",
      "Batch 1 + Batch 2 Train: 8116, Test: 909, Total: 8720\n",
      "‚úÖ Train and test sets successfully corrected and saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"/Users/gbaldonado/Developer/ml-alma-taccti/ml-alma-taccti/src/data_preprocessing/prepare_sentence_level/aspirational_plus_batch_1_batch_2_merged.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Ensure 'batch' column is a string\n",
    "df[\"batch\"] = df[\"batch\"].astype(str)\n",
    "\n",
    "# Split Batch 1 only\n",
    "batch1_df = df[df[\"batch\"] == \"batch_1\"]\n",
    "\n",
    "# Perform train-test split for Batch 1 (keeping stratification)\n",
    "train_batch1, test_batch1 = train_test_split(batch1_df, test_size=0.22, random_state=42, stratify=batch1_df[\"label\"])\n",
    "\n",
    "# Verify counts\n",
    "print(f\"Batch 1 Train: {len(train_batch1)}, Test: {len(test_batch1)}, Total: {len(batch1_df)}\")\n",
    "\n",
    "# Ensure all sentences in Batch 1 train/test are also in Batch 1 + Batch 2\n",
    "batch1_2_df = df  # Full dataset (Batch 1 + Batch 2)\n",
    "\n",
    "# --- üõ†Ô∏è **Fix for incorrect filtering** ---\n",
    "# Step 1: Retrieve all Batch 1 sentences from Batch 1+2\n",
    "train_batch1_2 = batch1_2_df[batch1_2_df[\"sentence\"].isin(train_batch1[\"sentence\"])]\n",
    "test_batch1_2 = batch1_2_df[batch1_2_df[\"sentence\"].isin(test_batch1[\"sentence\"])]\n",
    "\n",
    "# Step 2: Add the remaining Batch 2 sentences (not already in train/test)\n",
    "batch2_df = df[df[\"batch\"] == \"batch_2\"]\n",
    "train_batch1_2 = pd.concat([train_batch1_2, batch2_df], ignore_index=True)\n",
    "\n",
    "# Verify counts match\n",
    "print(f\"Batch 1 + Batch 2 Train: {len(train_batch1_2)}, Test: {len(test_batch1_2)}, Total: {len(batch1_2_df)}\")\n",
    "\n",
    "# # Save final DataFrames\n",
    "train_batch1.to_excel(\"/Users/gbaldonado/Developer/ml-alma-taccti/ml-alma-taccti/src/data_preprocessing/prepare_sentence_level/train_batch1.xlsx\", index=False)\n",
    "test_batch1.to_excel(\"/Users/gbaldonado/Developer/ml-alma-taccti/ml-alma-taccti/src/data_preprocessing/prepare_sentence_level/test_batch1.xlsx\", index=False)\n",
    "train_batch1_2.to_excel(\"/Users/gbaldonado/Developer/ml-alma-taccti/ml-alma-taccti/src/data_preprocessing/prepare_sentence_level/train_batch1_2.xlsx\", index=False)\n",
    "test_batch1_2.to_excel(\"/Users/gbaldonado/Developer/ml-alma-taccti/ml-alma-taccti/src/data_preprocessing/prepare_sentence_level/test_batch1_2.xlsx\", index=False)\n",
    "\n",
    "print(\"‚úÖ Train and test sets successfully corrected and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_batch1['sentence']\n",
    "y = train_batch1['original_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 18, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'distilbert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 20\n",
      "\t95percentile : 39\n",
      "\t99percentile : 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 21\n",
      "\t95percentile : 41\n",
      "\t99percentile : 55\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distillbert_transformer = text.Transformer(model_name, maxlen=MAXLEN, class_names=[0,1])\n",
    "training_set = distillbert_transformer.preprocess_train(X_train.tolist(), y_train.tolist())\n",
    "validation_set = distillbert_transformer.preprocess_test(X_test.tolist(), y_test.tolist())\n",
    "distillbert_base_model = distillbert_transformer.get_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillbert_learner = ktrain.get_learner(distillbert_base_model, train_data=training_set, val_data=validation_set, batch_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using triangular learning rate policy with max lr of 2e-05...\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 91s 222ms/step - loss: 0.4547 - accuracy: 0.7955 - val_loss: 0.4150 - val_accuracy: 0.8059\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 87s 235ms/step - loss: 0.3022 - accuracy: 0.8840 - val_loss: 0.4319 - val_accuracy: 0.8077\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 94s 257ms/step - loss: 0.2147 - accuracy: 0.9271 - val_loss: 0.4699 - val_accuracy: 0.7949\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 96s 263ms/step - loss: 0.1322 - accuracy: 0.9569 - val_loss: 0.5380 - val_accuracy: 0.7967\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 93s 253ms/step - loss: 0.0782 - accuracy: 0.9762 - val_loss: 0.6728 - val_accuracy: 0.8022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x3cf62dee0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distillbert_learner.autofit(2e-5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 234ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87       409\n",
      "           1       0.59      0.67      0.63       137\n",
      "\n",
      "    accuracy                           0.80       546\n",
      "   macro avg       0.74      0.76      0.75       546\n",
      "weighted avg       0.81      0.80      0.81       546\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[346,  63],\n",
       "       [ 45,  92]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distillbert_learner.validate(class_names=distillbert_transformer.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMa  multiple                  66362880  \n",
      " inLayer)                                                        \n",
      "                                                                 \n",
      " pre_classifier (Dense)      multiple                  590592    \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      " dropout_79 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66955010 (255.41 MB)\n",
      "Trainable params: 66955010 (255.41 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "distillbert_learner.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillbert_predictor = ktrain.get_predictor(distillbert_learner.model, preproc=distillbert_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillbert_test_data = test_batch1['sentence'].tolist()\n",
    "distillbert_test_label = test_batch1['original_label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_distillbert = distillbert_predictor.predict(distillbert_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_distillbert = [int(x) for x in y_pred_distillbert]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative: 503, False Positive: 67, False Negative: 70, True Positive: 130\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(distillbert_test_label, y_pred_distillbert).ravel()\n",
    "print('True Negative: {}, False Positive: {}, False Negative: {}, True Positive: {}'.format(tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       570\n",
      "           1       0.66      0.65      0.65       200\n",
      "\n",
      "    accuracy                           0.82       770\n",
      "   macro avg       0.77      0.77      0.77       770\n",
      "weighted avg       0.82      0.82      0.82       770\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('  Classification Report:\\n',classification_report(distillbert_test_label,y_pred_distillbert),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       582\n",
      "           1       0.70      0.66      0.68       188\n",
      "\n",
      "    accuracy                           0.85       770\n",
      "   macro avg       0.80      0.79      0.79       770\n",
      "weighted avg       0.85      0.85      0.85       770\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('  Classification Report:\\n',classification_report(distillbert_test_label,y_pred_distillbert),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distillbert_predictor.save('./model/distilbert_base_uncased_model') # 256 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC roc score for distillbert model:  0.8009703180009733\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC roc score for distillbert model: \", roc_auc_score(distillbert_test_label,y_pred_distillbert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
