{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ktrain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>phrase</th>\n",
       "      <th>batch</th>\n",
       "      <th>original_label</th>\n",
       "      <th>changed?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>why am i here?</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"ever since i was little i wanted to be a doc...</td>\n",
       "      <td>batch_1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>well why does anyone pursue a higher education?</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"ever since i was little i wanted to be a doc...</td>\n",
       "      <td>batch_1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to better one self and be able to succeed late...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"ever since i was little i wanted to be a doc...</td>\n",
       "      <td>batch_1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ever since i was little i wanted to be a docto...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"ever since i was little i wanted to be a doc...</td>\n",
       "      <td>batch_1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i always wanted to be able to help people and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"ever since i was little i wanted to be a doc...</td>\n",
       "      <td>batch_1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8715</th>\n",
       "      <td>anyways, the path im referring to is basically...</td>\n",
       "      <td>0</td>\n",
       "      <td>['one of these goals is being in a career i en...</td>\n",
       "      <td>batch_2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8716</th>\n",
       "      <td>i know that i want a career in which ill help ...</td>\n",
       "      <td>0</td>\n",
       "      <td>['one of these goals is being in a career i en...</td>\n",
       "      <td>batch_2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8717</th>\n",
       "      <td>in any case, i intend to keep moving forward i...</td>\n",
       "      <td>0</td>\n",
       "      <td>['one of these goals is being in a career i en...</td>\n",
       "      <td>batch_2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8718</th>\n",
       "      <td>i am here to fulfill a covenant with myself an...</td>\n",
       "      <td>1</td>\n",
       "      <td>['i am here to fulfill a covenant with myself ...</td>\n",
       "      <td>batch_2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8719</th>\n",
       "      <td>i am here to be a learned person.i am here to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>['i am here to fulfill a covenant with myself ...</td>\n",
       "      <td>batch_2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8720 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label  \\\n",
       "0                                        why am i here?      0   \n",
       "1       well why does anyone pursue a higher education?      0   \n",
       "2     to better one self and be able to succeed late...      1   \n",
       "3     ever since i was little i wanted to be a docto...      1   \n",
       "4     i always wanted to be able to help people and ...      1   \n",
       "...                                                 ...    ...   \n",
       "8715  anyways, the path im referring to is basically...      0   \n",
       "8716  i know that i want a career in which ill help ...      0   \n",
       "8717  in any case, i intend to keep moving forward i...      0   \n",
       "8718  i am here to fulfill a covenant with myself an...      1   \n",
       "8719  i am here to be a learned person.i am here to ...      1   \n",
       "\n",
       "                                                 phrase    batch  \\\n",
       "0     [\"ever since i was little i wanted to be a doc...  batch_1   \n",
       "1     [\"ever since i was little i wanted to be a doc...  batch_1   \n",
       "2     [\"ever since i was little i wanted to be a doc...  batch_1   \n",
       "3     [\"ever since i was little i wanted to be a doc...  batch_1   \n",
       "4     [\"ever since i was little i wanted to be a doc...  batch_1   \n",
       "...                                                 ...      ...   \n",
       "8715  ['one of these goals is being in a career i en...  batch_2   \n",
       "8716  ['one of these goals is being in a career i en...  batch_2   \n",
       "8717  ['one of these goals is being in a career i en...  batch_2   \n",
       "8718  ['i am here to fulfill a covenant with myself ...  batch_2   \n",
       "8719  ['i am here to fulfill a covenant with myself ...  batch_2   \n",
       "\n",
       "      original_label  changed?  \n",
       "0                  0     False  \n",
       "1                  0     False  \n",
       "2                  1     False  \n",
       "3                  1     False  \n",
       "4                  1     False  \n",
       "...              ...       ...  \n",
       "8715               0     False  \n",
       "8716               0     False  \n",
       "8717               0     False  \n",
       "8718               1     False  \n",
       "8719               1     False  \n",
       "\n",
       "[8720 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspirational_df = pd.read_excel('/Users/gbaldonado/Developer/ml-alma-taccti/ml-alma-taccti/src/data_preprocessing/prepare_sentence_level/aspirational_plus_batch_1_batch_2_merged.xlsx')\n",
    "aspirational_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>phrase</th>\n",
       "      <th>batch</th>\n",
       "      <th>original_label</th>\n",
       "      <th>changed?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>why am i here?</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"ever since i was little i wanted to be a doc...</td>\n",
       "      <td>batch_1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>well why does anyone pursue a higher education?</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"ever since i was little i wanted to be a doc...</td>\n",
       "      <td>batch_1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to better one self and be able to succeed late...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"ever since i was little i wanted to be a doc...</td>\n",
       "      <td>batch_1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ever since i was little i wanted to be a docto...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"ever since i was little i wanted to be a doc...</td>\n",
       "      <td>batch_1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i always wanted to be able to help people and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"ever since i was little i wanted to be a doc...</td>\n",
       "      <td>batch_1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492</th>\n",
       "      <td>i want to better myself, improve myself in eve...</td>\n",
       "      <td>1</td>\n",
       "      <td>['i want to be able to apply my knowledge to m...</td>\n",
       "      <td>batch_1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>i have no problems applying myself when it com...</td>\n",
       "      <td>0</td>\n",
       "      <td>['i want to be able to apply my knowledge to m...</td>\n",
       "      <td>batch_1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>grow mentally so that i can apply more physica...</td>\n",
       "      <td>0</td>\n",
       "      <td>['i want to be able to apply my knowledge to m...</td>\n",
       "      <td>batch_1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>use what i learn and apply it in whatever care...</td>\n",
       "      <td>0</td>\n",
       "      <td>['i want to be able to apply my knowledge to m...</td>\n",
       "      <td>batch_1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>the more i learn the more opportunities are av...</td>\n",
       "      <td>0</td>\n",
       "      <td>['i want to be able to apply my knowledge to m...</td>\n",
       "      <td>batch_1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3497 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label  \\\n",
       "0                                        why am i here?      0   \n",
       "1       well why does anyone pursue a higher education?      0   \n",
       "2     to better one self and be able to succeed late...      1   \n",
       "3     ever since i was little i wanted to be a docto...      1   \n",
       "4     i always wanted to be able to help people and ...      1   \n",
       "...                                                 ...    ...   \n",
       "3492  i want to better myself, improve myself in eve...      1   \n",
       "3493  i have no problems applying myself when it com...      0   \n",
       "3494  grow mentally so that i can apply more physica...      0   \n",
       "3495  use what i learn and apply it in whatever care...      0   \n",
       "3496  the more i learn the more opportunities are av...      0   \n",
       "\n",
       "                                                 phrase    batch  \\\n",
       "0     [\"ever since i was little i wanted to be a doc...  batch_1   \n",
       "1     [\"ever since i was little i wanted to be a doc...  batch_1   \n",
       "2     [\"ever since i was little i wanted to be a doc...  batch_1   \n",
       "3     [\"ever since i was little i wanted to be a doc...  batch_1   \n",
       "4     [\"ever since i was little i wanted to be a doc...  batch_1   \n",
       "...                                                 ...      ...   \n",
       "3492  ['i want to be able to apply my knowledge to m...  batch_1   \n",
       "3493  ['i want to be able to apply my knowledge to m...  batch_1   \n",
       "3494  ['i want to be able to apply my knowledge to m...  batch_1   \n",
       "3495  ['i want to be able to apply my knowledge to m...  batch_1   \n",
       "3496  ['i want to be able to apply my knowledge to m...  batch_1   \n",
       "\n",
       "      original_label  changed?  \n",
       "0                  0     False  \n",
       "1                  0     False  \n",
       "2                  1     False  \n",
       "3                  1     False  \n",
       "4                  1     False  \n",
       "...              ...       ...  \n",
       "3492               1     False  \n",
       "3493               0     False  \n",
       "3494               0     False  \n",
       "3495               0     False  \n",
       "3496               0     False  \n",
       "\n",
       "[3497 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 Train: 2727, Test: 770, Total: 3497\n",
      "Batch 1 + Batch 2 Train: 2893, Test: 909, Total: 8720\n",
      "âœ… Train and test sets successfully created and saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"/Users/gbaldonado/Developer/ml-alma-taccti/ml-alma-taccti/src/data_preprocessing/prepare_sentence_level/aspirational_plus_batch_1_batch_2_merged.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Ensure 'batch' column is a string\n",
    "df[\"batch\"] = df[\"batch\"].astype(str)\n",
    "\n",
    "# Split Batch 1 only\n",
    "batch1_df = df[df[\"batch\"] == \"batch_1\"]\n",
    "\n",
    "# Perform train-test split for Batch 1 (keeping stratification)\n",
    "train_batch1, test_batch1 = train_test_split(batch1_df, test_size=0.22, random_state=42, stratify=batch1_df[\"label\"])\n",
    "\n",
    "# Verify counts\n",
    "print(f\"Batch 1 Train: {len(train_batch1)}, Test: {len(test_batch1)}, Total: {len(batch1_df)}\")\n",
    "\n",
    "# Ensure all sentences in Batch 1 train/test are found in Batch 1 + Batch 2\n",
    "batch1_2_df = df  # Full dataset (Batch 1 + Batch 2)\n",
    "\n",
    "# Use the same sentences from Batch 1 train in Batch 1 + Batch 2 train\n",
    "train_batch1_2 = batch1_2_df[batch1_2_df[\"sentence\"].isin(train_batch1[\"sentence\"])]\n",
    "\n",
    "# Use the same sentences from Batch 1 test in Batch 1 + Batch 2 test\n",
    "test_batch1_2 = batch1_2_df[batch1_2_df[\"sentence\"].isin(test_batch1[\"sentence\"])]\n",
    "\n",
    "# Verify counts match\n",
    "print(f\"Batch 1 + Batch 2 Train: {len(train_batch1_2)}, Test: {len(test_batch1_2)}, Total: {len(batch1_2_df)}\")\n",
    "\n",
    "# Save final DataFrames\n",
    "train_batch1.to_excel(\"/Users/gbaldonado/Developer/ml-alma-taccti/ml-alma-taccti/src/data_preprocessing/prepare_sentence_level/train_batch1.xlsx\", index=False)\n",
    "test_batch1.to_excel(\"/Users/gbaldonado/Developer/ml-alma-taccti/ml-alma-taccti/src/data_preprocessing/prepare_sentence_level/test_batch1.xlsx\", index=False)\n",
    "train_batch1_2.to_excel(\"/Users/gbaldonado/Developer/ml-alma-taccti/ml-alma-taccti/src/data_preprocessing/prepare_sentence_level/train_batch1_2.xlsx\", index=False)\n",
    "test_batch1_2.to_excel(\"/Users/gbaldonado/Developer/ml-alma-taccti/ml-alma-taccti/src/data_preprocessing/prepare_sentence_level/test_batch1_2.xlsx\", index=False)\n",
    "\n",
    "print(\"âœ… Train and test sets successfully created and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_batch1['sentence']\n",
    "y = train_batch1['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 18, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'distilbert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 20\n",
      "\t95percentile : 39\n",
      "\t99percentile : 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 21\n",
      "\t95percentile : 40\n",
      "\t99percentile : 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distillbert_transformer = text.Transformer(model_name, maxlen=MAXLEN, class_names=[0,1])\n",
    "training_set = distillbert_transformer.preprocess_train(X_train.tolist(), y_train.tolist())\n",
    "validation_set = distillbert_transformer.preprocess_test(X_test.tolist(), y_test.tolist())\n",
    "distillbert_base_model = distillbert_transformer.get_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillbert_learner = ktrain.get_learner(distillbert_base_model, train_data=training_set, val_data=validation_set, batch_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using triangular learning rate policy with max lr of 2e-05...\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 82s 200ms/step - loss: 0.4537 - accuracy: 0.7886 - val_loss: 0.3629 - val_accuracy: 0.8443\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 67s 182ms/step - loss: 0.3068 - accuracy: 0.8739 - val_loss: 0.3667 - val_accuracy: 0.8553\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 70s 191ms/step - loss: 0.2187 - accuracy: 0.9202 - val_loss: 0.4123 - val_accuracy: 0.8388\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 64s 174ms/step - loss: 0.1337 - accuracy: 0.9551 - val_loss: 0.4675 - val_accuracy: 0.8516\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 64s 173ms/step - loss: 0.0961 - accuracy: 0.9688 - val_loss: 0.5172 - val_accuracy: 0.8315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x362189130>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distillbert_learner.autofit(2e-5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 4s 180ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89       413\n",
      "           1       0.65      0.67      0.66       133\n",
      "\n",
      "    accuracy                           0.83       546\n",
      "   macro avg       0.77      0.78      0.77       546\n",
      "weighted avg       0.83      0.83      0.83       546\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[365,  48],\n",
       "       [ 44,  89]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distillbert_learner.validate(class_names=distillbert_transformer.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 161ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89       413\n",
      "           1       0.65      0.67      0.66       133\n",
      "\n",
      "    accuracy                           0.83       546\n",
      "   macro avg       0.77      0.78      0.77       546\n",
      "weighted avg       0.83      0.83      0.83       546\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[365,  48],\n",
       "       [ 44,  89]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distillbert_learner.validate(class_names=distillbert_transformer.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMa  multiple                  66362880  \n",
      " inLayer)                                                        \n",
      "                                                                 \n",
      " pre_classifier (Dense)      multiple                  590592    \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      " dropout_119 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66955010 (255.41 MB)\n",
      "Trainable params: 66955010 (255.41 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "distillbert_learner.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillbert_predictor = ktrain.get_predictor(distillbert_learner.model, preproc=distillbert_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillbert_test_data = test_batch1['sentence'].tolist()\n",
    "distillbert_test_label = test_batch1['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_distillbert = distillbert_predictor.predict(distillbert_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_distillbert = [int(x) for x in y_pred_distillbert]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative: 509, False Positive: 73, False Negative: 55, True Positive: 133\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(distillbert_test_label, y_pred_distillbert).ravel()\n",
    "print('True Negative: {}, False Positive: {}, False Negative: {}, True Positive: {}'.format(tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89       582\n",
      "           1       0.65      0.71      0.68       188\n",
      "\n",
      "    accuracy                           0.83       770\n",
      "   macro avg       0.77      0.79      0.78       770\n",
      "weighted avg       0.84      0.83      0.84       770\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('  Classification Report:\\n',classification_report(distillbert_test_label,y_pred_distillbert),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95       117\n",
      "           1       0.72      0.92      0.81        25\n",
      "\n",
      "    accuracy                           0.92       142\n",
      "   macro avg       0.85      0.92      0.88       142\n",
      "weighted avg       0.94      0.92      0.93       142\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('  Classification Report:\\n',classification_report(distillbert_test_label,y_pred_distillbert),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distillbert_predictor.save('./model/distilbert_base_uncased_model') # 256 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC roc score for distillbert model:  0.7910086276230168\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC roc score for distillbert model: \", roc_auc_score(distillbert_test_label,y_pred_distillbert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
