{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ktrain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ktrain import text\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"/Users/gbaldonado/Developer/ml-alma-taccti/ml-alma-taccti/data/for_training/merged/Resistance_plus_batch_1_batch_2_merged.xlsx\"\n",
    "resistance_df = pd.read_excel(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resistance Train: 2208, Test: 624, Total: 2832\n",
      "ðŸ“Š resistance Dataset Train-Test Split Results:\n",
      "âœ… Train: 2208 samples (Positives: 652, 29.53%)\n",
      "âœ… Test: 624 samples (Positives: 184, 29.49%)\n",
      "ðŸ”¹ Total Dataset: 2832 samples\n",
      "âœ… resistance train and test sets successfully created and saved!\n"
     ]
    }
   ],
   "source": [
    "# Perform train-test split (keeping stratification)\n",
    "train_resistance, test_resistance = train_test_split(\n",
    "    resistance_df, test_size=0.22, random_state=42, stratify=resistance_df[\"label\"]\n",
    ")\n",
    "\n",
    "# Verify counts\n",
    "print(f\"resistance Train: {len(train_resistance)}, Test: {len(test_resistance)}, Total: {len(resistance_df)}\")\n",
    "\n",
    "# Count total samples\n",
    "total_train = len(train_resistance)\n",
    "total_test = len(test_resistance)\n",
    "\n",
    "# Count positive (Class 1) samples\n",
    "train_positives = train_resistance[\"label\"].sum()\n",
    "test_positives = test_resistance[\"label\"].sum()\n",
    "\n",
    "# Calculate percentages\n",
    "train_positive_pct = (train_positives / total_train) * 100\n",
    "test_positive_pct = (test_positives / total_test) * 100\n",
    "\n",
    "# Print results\n",
    "print(f\"ðŸ“Š resistance Dataset Train-Test Split Results:\")\n",
    "print(f\"âœ… Train: {total_train} samples (Positives: {train_positives}, {train_positive_pct:.2f}%)\")\n",
    "print(f\"âœ… Test: {total_test} samples (Positives: {test_positives}, {test_positive_pct:.2f}%)\")\n",
    "print(f\"ðŸ”¹ Total Dataset: {len(resistance_df)} samples\")\n",
    "\n",
    "\n",
    "# Define save directory\n",
    "save_dir = \"/Users/gbaldonado/Developer/ml-alma-taccti/ml-alma-taccti/data/for_training/merged/res_train_test\"\n",
    "os.makedirs(save_dir, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "# Save train and test sets\n",
    "train_resistance.to_excel(f\"{save_dir}/train_resistance.xlsx\", index=False)\n",
    "test_resistance.to_excel(f\"{save_dir}/test_resistance.xlsx\", index=False)\n",
    "\n",
    "print(\"âœ… resistance train and test sets successfully created and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_resistance['sentence']\n",
    "y = train_resistance['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 18, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'microsoft/deberta-v3-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 21\n",
      "\t95percentile : 41\n",
      "\t99percentile : 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gbaldonado/miniforge3/envs/ml_env/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:562: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 21\n",
      "\t95percentile : 40\n",
      "\t99percentile : 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distillbert_transformer = text.Transformer(model_name, maxlen=MAXLEN, class_names=[0,1])\n",
    "training_set = distillbert_transformer.preprocess_train(X_train.tolist(), y_train.tolist())\n",
    "validation_set = distillbert_transformer.preprocess_test(X_test.tolist(), y_test.tolist())\n",
    "distillbert_base_model = distillbert_transformer.get_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillbert_learner = ktrain.get_learner(distillbert_base_model, train_data=training_set, val_data=validation_set, batch_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using triangular learning rate policy with max lr of 2e-05...\n",
      "Epoch 1/5\n",
      "295/295 [==============================] - 1041s 3s/step - loss: 0.6260 - accuracy: 0.6716 - val_loss: 0.6011 - val_accuracy: 0.7036\n",
      "Epoch 2/5\n",
      " 25/295 [=>............................] - ETA: 23:16 - loss: 0.5951 - accuracy: 0.7133"
     ]
    }
   ],
   "source": [
    "distillbert_learner.autofit(2e-5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 6s 262ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       306\n",
      "           1       0.77      0.76      0.76        87\n",
      "\n",
      "    accuracy                           0.90       393\n",
      "   macro avg       0.85      0.85      0.85       393\n",
      "weighted avg       0.90      0.90      0.90       393\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[286,  20],\n",
       "       [ 21,  66]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distillbert_learner.validate(class_names=distillbert_transformer.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMa  multiple                  66362880  \n",
      " inLayer)                                                        \n",
      "                                                                 \n",
      " pre_classifier (Dense)      multiple                  590592    \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66955010 (255.41 MB)\n",
      "Trainable params: 66955010 (255.41 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "distillbert_learner.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillbert_predictor = ktrain.get_predictor(distillbert_learner.model, preproc=distillbert_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillbert_test_data = test_resistance['sentence'].tolist()\n",
    "distillbert_test_label = test_resistance['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_distillbert = distillbert_predictor.predict(distillbert_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_distillbert = [int(x) for x in y_pred_distillbert]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative: 411, False Positive: 21, False Negative: 19, True Positive: 104\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(distillbert_test_label, y_pred_distillbert).ravel()\n",
    "print('True Negative: {}, False Positive: {}, False Negative: {}, True Positive: {}'.format(tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       432\n",
      "           1       0.83      0.85      0.84       123\n",
      "\n",
      "    accuracy                           0.93       555\n",
      "   macro avg       0.89      0.90      0.90       555\n",
      "weighted avg       0.93      0.93      0.93       555\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('  Classification Report:\\n',classification_report(distillbert_test_label,y_pred_distillbert),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95       117\n",
      "           1       0.72      0.92      0.81        25\n",
      "\n",
      "    accuracy                           0.92       142\n",
      "   macro avg       0.85      0.92      0.88       142\n",
      "weighted avg       0.94      0.92      0.93       142\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('  Classification Report:\\n',classification_report(distillbert_test_label,y_pred_distillbert),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distillbert_predictor.save('./model/distilbert_base_uncased_model') # 256 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC roc score for distillbert model:  0.8009703180009733\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC roc score for distillbert model: \", roc_auc_score(distillbert_test_label,y_pred_distillbert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
