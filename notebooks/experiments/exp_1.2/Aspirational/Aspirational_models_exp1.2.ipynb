{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aspirational Models Experiment 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import warnings\n",
    "import spacy\n",
    "import nltk\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Set random seed\n",
    "random.seed(18)\n",
    "seed = 18\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/gbaldonado/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize spaCy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the data and quick exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_aspirational_df = pd.read_csv(\"/Users/gbaldonado/Developer/ml-alma-taccti/ml-alma-taccti/data/processed_for_model/merged_themes_using_jaccard_method/merged_Aspirational_sentence_level_batch_1_jaccard.csv\", encoding='utf-8')\n",
    "\n",
    "# Shuffle the merged dataset\n",
    "merged_aspirational_df = shuffle(merged_aspirational_df, random_state=seed)\n",
    "\n",
    "# # Train-test split \n",
    "# training_df, test_df = train_test_split(merged_aspirational_df, test_size=0.1, random_state=18, stratify=merged_aspirational_df['label'])\n",
    "\n",
    "# training_df.reset_index(drop=True, inplace=True)\n",
    "# test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords for attainment and aspiration\n",
    "attainment_keywords = ['degree', 'grades', 'career', 'job', 'medical school', 'achieve', 'CV', 'resume']\n",
    "aspiration_keywords = ['goal', 'dream', 'hope', 'aspire', 'motivated', 'ambition', 'understanding', 'better person']\n",
    "\n",
    "def keyword_features(text):\n",
    "    features = {}\n",
    "    for keyword in attainment_keywords:\n",
    "        features[f'attainment_{keyword}'] = int(keyword in text.lower())\n",
    "    for keyword in aspiration_keywords:\n",
    "        features[f'aspiration_{keyword}'] = int(keyword in text.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependency_features(doc):\n",
    "    features = {}\n",
    "    for token in doc:\n",
    "        if token.dep_ in ['nsubj', 'dobj', 'iobj', 'amod']:\n",
    "            features[f'deprel_{token.dep_}_{token.text}'] = 1\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_features(doc):\n",
    "    features = {}\n",
    "    for token in doc:\n",
    "        features[f'pos_{token.pos_}_{token.text}'] = 1\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# N-gram vectorizer function\n",
    "def ngram_features(corpus, ngram_range=(1, 2)):\n",
    "    vectorizer = CountVectorizer(ngram_range=ngram_range, tokenizer=word_tokenize)\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    feature_names = [str(i + 1) for i in range(X.shape[1])]  # Naming features as '1', '2', '3', ...\n",
    "    return X, feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model on your corpus\n",
    "def get_word2vec(corpus):\n",
    "    tokenized_corpus = [word_tokenize(sentence) for sentence in corpus]\n",
    "    model = Word2Vec(sentences=tokenized_corpus, vector_size=100, window=5, min_count=1, workers=4)\n",
    "    return model\n",
    "\n",
    "# Get the average word vector for a sentence\n",
    "def sentence_vector(sentence, model):\n",
    "    words = word_tokenize(sentence)\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(word_vectors, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all feature extraction functions\n",
    "def extract_features(df, word2vec_model, ngram_range=(1, 2)):\n",
    "    keyword_feats = []\n",
    "    dependency_feats = []\n",
    "    pos_feats = []\n",
    "    sent_vectors = []\n",
    "    \n",
    "    for text in df['sentence']:\n",
    "        doc = nlp(text)\n",
    "        \n",
    "        # Keyword features\n",
    "        kw_features = keyword_features(text)\n",
    "        keyword_feats.append(kw_features)\n",
    "        \n",
    "        # Dependency features\n",
    "        dep_features = dependency_features(doc)\n",
    "        dependency_feats.append(dep_features)\n",
    "        \n",
    "        # POS features\n",
    "        pos_features_dict = pos_features(doc)\n",
    "        pos_feats.append(pos_features_dict)\n",
    "        \n",
    "        # Sentence vector (semantic similarity)\n",
    "        sent_vector = sentence_vector(text, word2vec_model)\n",
    "        sent_vectors.append(sent_vector)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    keyword_df = pd.DataFrame(keyword_feats).fillna(0)\n",
    "    dependency_df = pd.DataFrame(dependency_feats).fillna(0)\n",
    "    pos_df = pd.DataFrame(pos_feats).fillna(0)\n",
    "    sent_vectors_df = pd.DataFrame(sent_vectors)\n",
    "    \n",
    "    # N-gram features\n",
    "    ngram_X, ngram_feature_names = ngram_features(df['sentence'], ngram_range)\n",
    "    \n",
    "    # Combine all features\n",
    "    keyword_df_sparse = csr_matrix(keyword_df)\n",
    "    dependency_df_sparse = csr_matrix(dependency_df)\n",
    "    pos_df_sparse = csr_matrix(pos_df)\n",
    "    sent_vectors_df_sparse = csr_matrix(sent_vectors_df)\n",
    "    \n",
    "    X_combined = hstack([keyword_df_sparse, dependency_df_sparse, pos_df_sparse, sent_vectors_df_sparse, ngram_X])\n",
    "    X_combined_df = pd.DataFrame.sparse.from_spmatrix(X_combined)\n",
    "    X_combined_df.columns = list(keyword_df.columns) + list(dependency_df.columns) + list(pos_df.columns) + list(sent_vectors_df.columns) + ngram_feature_names\n",
    "    \n",
    "    return X_combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = merged_aspirational_df['sentence'].tolist()\n",
    "word2vec_model = get_word2vec(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "feature_df = extract_features(merged_aspirational_df, word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([        'attainment_degree',         'attainment_grades',\n",
       "               'attainment_career',            'attainment_job',\n",
       "       'attainment_medical school',        'attainment_achieve',\n",
       "                   'attainment_CV',         'attainment_resume',\n",
       "                 'aspiration_goal',          'aspiration_dream',\n",
       "       ...\n",
       "                           '30298',                     '30299',\n",
       "                           '30300',                     '30301',\n",
       "                           '30302',                     '30303',\n",
       "                           '30304',                     '30305',\n",
       "                           '30306',                     '30307'],\n",
       "      dtype='object', length=36900)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attainment_degree</th>\n",
       "      <th>attainment_grades</th>\n",
       "      <th>attainment_career</th>\n",
       "      <th>attainment_job</th>\n",
       "      <th>attainment_medical school</th>\n",
       "      <th>attainment_achieve</th>\n",
       "      <th>attainment_CV</th>\n",
       "      <th>attainment_resume</th>\n",
       "      <th>aspiration_goal</th>\n",
       "      <th>aspiration_dream</th>\n",
       "      <th>...</th>\n",
       "      <th>30299</th>\n",
       "      <th>30300</th>\n",
       "      <th>30301</th>\n",
       "      <th>30302</th>\n",
       "      <th>30303</th>\n",
       "      <th>30304</th>\n",
       "      <th>30305</th>\n",
       "      <th>30306</th>\n",
       "      <th>30307</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4699</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4700</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4701</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4702</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4703</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4704 rows × 36901 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      attainment_degree  attainment_grades  attainment_career  attainment_job  \\\n",
       "0                   0.0                0.0                0.0             0.0   \n",
       "1                   1.0                0.0                0.0             0.0   \n",
       "2                   0.0                0.0                0.0             0.0   \n",
       "3                   0.0                0.0                0.0             0.0   \n",
       "4                   0.0                0.0                0.0             0.0   \n",
       "...                 ...                ...                ...             ...   \n",
       "4699                0.0                0.0                0.0             0.0   \n",
       "4700                0.0                0.0                0.0             0.0   \n",
       "4701                1.0                0.0                0.0             0.0   \n",
       "4702                0.0                0.0                0.0             0.0   \n",
       "4703                0.0                0.0                0.0             0.0   \n",
       "\n",
       "      attainment_medical school  attainment_achieve  attainment_CV  \\\n",
       "0                           0.0                 0.0            0.0   \n",
       "1                           0.0                 0.0            0.0   \n",
       "2                           0.0                 0.0            0.0   \n",
       "3                           0.0                 0.0            0.0   \n",
       "4                           0.0                 0.0            0.0   \n",
       "...                         ...                 ...            ...   \n",
       "4699                        0.0                 0.0            0.0   \n",
       "4700                        0.0                 0.0            0.0   \n",
       "4701                        0.0                 0.0            0.0   \n",
       "4702                        0.0                 0.0            0.0   \n",
       "4703                        0.0                 0.0            0.0   \n",
       "\n",
       "      attainment_resume  aspiration_goal  aspiration_dream  ...  30299  30300  \\\n",
       "0                   0.0              0.0               0.0  ...    0.0    0.0   \n",
       "1                   0.0              0.0               0.0  ...    0.0    0.0   \n",
       "2                   0.0              0.0               0.0  ...    0.0    0.0   \n",
       "3                   0.0              0.0               0.0  ...    0.0    0.0   \n",
       "4                   0.0              0.0               0.0  ...    0.0    0.0   \n",
       "...                 ...              ...               ...  ...    ...    ...   \n",
       "4699                0.0              0.0               0.0  ...    0.0    0.0   \n",
       "4700                0.0              0.0               0.0  ...    0.0    0.0   \n",
       "4701                0.0              1.0               0.0  ...    0.0    0.0   \n",
       "4702                0.0              0.0               0.0  ...    0.0    0.0   \n",
       "4703                0.0              0.0               0.0  ...    0.0    0.0   \n",
       "\n",
       "      30301  30302  30303  30304  30305  30306  30307  label  \n",
       "0       0.0    0.0    0.0    0.0    0.0    0.0    0.0      0  \n",
       "1       0.0    0.0    0.0    0.0    0.0    0.0    0.0      0  \n",
       "2       0.0    0.0    0.0    0.0    0.0    0.0    0.0      0  \n",
       "3       0.0    0.0    0.0    0.0    0.0    0.0    0.0      1  \n",
       "4       0.0    0.0    0.0    0.0    0.0    0.0    0.0      0  \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "4699    0.0    0.0    0.0    0.0    0.0    0.0    0.0      0  \n",
       "4700    0.0    0.0    0.0    0.0    0.0    0.0    0.0      0  \n",
       "4701    0.0    0.0    0.0    0.0    0.0    0.0    0.0      0  \n",
       "4702    0.0    0.0    0.0    0.0    0.0    0.0    0.0      0  \n",
       "4703    0.0    0.0    0.0    0.0    0.0    0.0    0.0      0  \n",
       "\n",
       "[4704 rows x 36901 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = merged_aspirational_df[\"label\"]\n",
    "\n",
    "# Combine extracted features with the label\n",
    "final_df = pd.concat([feature_df, pd.Series(labels, name='label')], axis=1)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns = final_df.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "X = final_df.drop('label', axis=1)\n",
    "y = final_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4233, 36900)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(471, 36900)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters for each model\n",
    "log_reg_params = {\n",
    "    'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__penalty' : [\"l2\"],\n",
    "    'classifier__solver': ['liblinear']\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [5, 10, 15],\n",
    "    'classifier__min_samples_split': [2, 10],\n",
    "    'classifier__min_samples_leaf': [1, 5]\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [3, 5, 7],\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.3]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifiers\n",
    "log_reg = Pipeline([\n",
    "    ('classifier', LogisticRegression(class_weight='balanced', max_iter=10000, random_state=seed))\n",
    "])\n",
    "\n",
    "rf = Pipeline([\n",
    "    ('classifier', RandomForestClassifier(class_weight='balanced', random_state=seed))\n",
    "])\n",
    "\n",
    "xgboost = Pipeline([\n",
    "    ('classifier', xgb.XGBClassifier(class_weight='balanced', random_state=seed, use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search with cross-validation\n",
    "def perform_grid_search(pipeline, params, X_train, y_train):\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=params, cv=10, n_jobs=-1, verbose=1, scoring='f1_macro')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(cm)\n",
    "    print(f\"True Positives: {tp}, False Positives: {fp}, True Negatives: {tn}, False Negatives: {fn}\")\n",
    "    # Classification report\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    print(class_report)\n",
    "    \n",
    "    return precision, recall, f1, cm, class_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "[[366  46]\n",
      " [ 56   3]]\n",
      "True Positives: 3, False Positives: 46, True Negatives: 366, False Negatives: 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       412\n",
      "           1       0.06      0.05      0.06        59\n",
      "\n",
      "    accuracy                           0.78       471\n",
      "   macro avg       0.46      0.47      0.47       471\n",
      "weighted avg       0.77      0.78      0.77       471\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "log_reg_grid = perform_grid_search(log_reg, log_reg_params, X_train, y_train)\n",
    "log_reg_precision, log_reg_recall, log_reg_f1, log_cm, log_class_report = evaluate_model(log_reg_grid, X_test, y_test)\n",
    "results.append({\n",
    "    'Algorithm': 'Logistic Regression',\n",
    "    'Avg Precision': log_reg_precision,\n",
    "    'Avg Recall': log_reg_recall,\n",
    "    'Macro F1 Score': log_reg_f1,\n",
    "    'Confusion Matrix': log_cm,\n",
    "    'classification_report': log_class_report,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "[[374  38]\n",
      " [ 56   3]]\n",
      "True Positives: 3, False Positives: 38, True Negatives: 374, False Negatives: 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       412\n",
      "           1       0.07      0.05      0.06        59\n",
      "\n",
      "    accuracy                           0.80       471\n",
      "   macro avg       0.47      0.48      0.47       471\n",
      "weighted avg       0.77      0.80      0.78       471\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[146], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Random Forest\u001b[39;00m\n\u001b[1;32m      2\u001b[0m rf_grid \u001b[38;5;241m=\u001b[39m perform_grid_search(rf, rf_params, X_train, y_train)\n\u001b[0;32m----> 3\u001b[0m rf_precision, rf_recall, rf_f1 \u001b[38;5;241m=\u001b[39m evaluate_model(rf_grid, X_test, y_test)\n\u001b[1;32m      4\u001b[0m results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlgorithm\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg Precision\u001b[39m\u001b[38;5;124m'\u001b[39m: rf_precision,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg Recall\u001b[39m\u001b[38;5;124m'\u001b[39m: rf_recall,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMacro F1 Score\u001b[39m\u001b[38;5;124m'\u001b[39m: rf_f1\n\u001b[1;32m      9\u001b[0m })\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_grid = perform_grid_search(rf, rf_params, X_train, y_train)\n",
    "rf_precision, rf_recall, rf_f1 = evaluate_model(rf_grid, X_test, y_test)\n",
    "results.append({\n",
    "    'Algorithm': 'Random Forest',\n",
    "    'Avg Precision': rf_precision,\n",
    "    'Avg Recall': rf_recall,\n",
    "    'Macro F1 Score': rf_f1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgb_grid = perform_grid_search(xgboost, xgb_params, X_train, y_train)\n",
    "xgb_precision, xgb_recall, xgb_f1 = evaluate_model(xgb_grid, X_test, y_test)\n",
    "results.append({\n",
    "    'Algorithm': 'XGBoost',\n",
    "    'Avg Precision': xgb_precision,\n",
    "    'Avg Recall': xgb_recall,\n",
    "    'Macro F1 Score': xgb_f1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
