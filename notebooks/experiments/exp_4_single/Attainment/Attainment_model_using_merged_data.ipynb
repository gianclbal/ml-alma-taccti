{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aspirational DistilBERT Model Using Single Batch 1 + Batch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ktrain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from ktrain import text\n",
    "import random\n",
    "import warnings\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Set random seed\n",
    "random.seed(18)\n",
    "seed = 18\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the data and quick exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Aspirational_sentence_level_batch_1_jaccard.csv\n",
      "Loaded Attainment_sentence_level_batch_1_jaccard.csv\n",
      "Loaded Community Consciousness_sentence_level_batch_1_jaccard.csv\n",
      "Loaded Familial_sentence_level_batch_1_jaccard.csv\n",
      "Loaded Filial Piety_sentence_level_batch_1_jaccard.csv\n",
      "Loaded First Gen_sentence_level_batch_1_jaccard.csv\n",
      "Loaded Navigational_sentence_level_batch_1_jaccard.csv\n",
      "Loaded Perseverance_sentence_level_batch_1_jaccard.csv\n",
      "Loaded Resistance_sentence_level_batch_1_jaccard.csv\n",
      "Loaded Social_sentence_level_batch_1_jaccard.csv\n",
      "Loaded Spiritual_sentence_level_batch_1_jaccard.csv\n",
      "Loaded Aspirational_sentence_level_batch_2_jaccard.csv\n",
      "Loaded Attainment_sentence_level_batch_2_jaccard.csv\n",
      "Loaded Community Consciouss_sentence_level_batch_2_jaccard.csv\n",
      "Loaded Familial_sentence_level_batch_2_jaccard.csv\n",
      "Loaded Filial Piety_sentence_level_batch_2_jaccard.csv\n",
      "Loaded First Generation_sentence_level_batch_2_jaccard.csv\n",
      "Loaded Navigational_sentence_level_batch_2_jaccard.csv\n",
      "Loaded Perseverance_sentence_level_batch_2_jaccard.csv\n",
      "Loaded Resistance_sentence_level_batch_2_jaccard.csv\n",
      "Loaded Social_sentence_level_batch_2_jaccard.csv\n",
      "Loaded Spiritual_sentence_level_batch_2_jaccard.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the folder path and themes\n",
    "folder_path = '/Users/gbaldonado/Developer/ml-alma-taccti/ml-alma-taccti/data/processed_for_model/single_theme_using_jaccard_method'\n",
    "themes = [\n",
    "    'Aspirational', 'Attainment', 'Community Consciousness', 'Familial', 'Filial Piety', \n",
    "    'First Gen', 'Navigational', 'Perseverance', 'Resistance', 'Social', 'Spiritual'\n",
    "]\n",
    "\n",
    "# Initialize an empty dictionary to store DataFrames\n",
    "batch_1_theme_dataframes = {}\n",
    "# Loop through each theme and load its corresponding file\n",
    "for theme in themes:\n",
    "    # Construct the filename without modifying the theme name\n",
    "    file_name = f\"{theme}_sentence_level_batch_1_jaccard.csv\"\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # Check if the file exists before attempting to load\n",
    "    if os.path.exists(file_path):\n",
    "        batch_1_theme_dataframes[theme] = pd.read_csv(file_path)\n",
    "        print(f\"Loaded {file_name}\")\n",
    "    else:\n",
    "        print(f\"File not found for theme: {theme}\")\n",
    "\n",
    "# Define the folder path and themes\n",
    "folder_path = '/Users/gbaldonado/Developer/ml-alma-taccti/ml-alma-taccti/data/processed_for_model/single_theme_using_jaccard_method/batch_2'\n",
    "themes = [\n",
    "    'Aspirational', 'Attainment', 'Community Consciouss', 'Familial', 'Filial Piety', \n",
    "    'First Generation', 'Navigational', 'Perseverance', 'Resistance', 'Social', 'Spiritual'\n",
    "]\n",
    "\n",
    "# Initialize an empty dictionary to store DataFrames\n",
    "batch_2_theme_dataframes = {}\n",
    "# Loop through each theme and load its corresponding file\n",
    "for theme in themes:\n",
    "    # Construct the filename without modifying the theme name\n",
    "    file_name = f\"{theme}_sentence_level_batch_2_jaccard.csv\"\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # Check if the file exists before attempting to load\n",
    "    if os.path.exists(file_path):\n",
    "        batch_2_theme_dataframes[theme] = pd.read_csv(file_path)\n",
    "        print(f\"Loaded {file_name}\")\n",
    "    else:\n",
    "        print(f\"File not found for theme: {theme}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspirational_df_batch_1 = batch_1_theme_dataframes[\"Attainment\"]\n",
    "aspirational_df_batch_2 = batch_2_theme_dataframes[\"Attainment\"]\n",
    "\n",
    "\n",
    "merged_aspirational_df = pd.concat([aspirational_df_batch_1, aspirational_df_batch_2])\n",
    "\n",
    "# Shuffle the merged dataset\n",
    "merged_aspirational_df = shuffle(merged_aspirational_df, random_state=seed)\n",
    "\n",
    "# Train-test split \n",
    "training_df, test_df = train_test_split(merged_aspirational_df, test_size=0.1, random_state=42, stratify=merged_aspirational_df['label'])\n",
    "\n",
    "training_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (4151, 3) \n",
      "Test dataset shape: (462, 3)\n",
      "Positive labels present in the dataset : 295  out of 4151 or 7.106721271982655%\n",
      "Positive labels present in the test dataset : 33  out of 462 or 7.142857142857142%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training dataset shape: {training_df.shape} \\nTest dataset shape: {test_df.shape}\")\n",
    "pos_labels = len([n for n in training_df['label'] if n==1])\n",
    "print(\"Positive labels present in the dataset : {}  out of {} or {}%\".format(pos_labels, len(training_df['label']), (pos_labels/len(training_df['label']))*100))\n",
    "pos_labels = len([n for n in test_df['label'] if n==1])\n",
    "print(\"Positive labels present in the test dataset : {}  out of {} or {}%\".format(pos_labels, len(test_df['label']), (pos_labels/len(test_df['label']))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>after working minimum wage part time jobs while in community college, i've learned that there is no way i can do that for the rest of my life.</td>\n",
       "      <td>0</td>\n",
       "      <td>['The bigger reason for why I am here as SF State is to get my degree to get a hopefully get a decent to well paying job when I graduate.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i struggle in day to day life and classes because of the grief.</td>\n",
       "      <td>0</td>\n",
       "      <td>['To be quite honest, this class is necessary for my degree and most likely to get into medical school. Its a shallow answer, but if I had to elaborate then I would say that this class is a step towards becoming a doctor. Ive wanted to become a doctor for as long as medical books have existed in libraries.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it here to learn new things, meet new people, and to be able to learn the culture and how is the america dream that a lot of people from the different country dream of.</td>\n",
       "      <td>0</td>\n",
       "      <td>['I am here to pursue my career of becoming an Electrical Engineering, and physics is one of the most important parts of it.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jordaan render phys 102 reflection 1 why am i here?</td>\n",
       "      <td>0</td>\n",
       "      <td>['I am here because I want to receive a quality education around a new group of people and further my academic career as well as personal character development. I would like to use my background in a way that allows me to me travel and connect with many different people from differing cultures and really gain a broader view on life. My current path is to become a Physical Therapist because I enjoy communicating with and helping people and as a PT, I will have many opportunities to travel for work.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am the first in my family to attempt to get into med school.</td>\n",
       "      <td>0</td>\n",
       "      <td>['I am here because of my goal in trying to get a B.S. in biology concentrated physiology.', 'Im here to become a doctor.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4146</th>\n",
       "      <td>i was not sure if i wanted to take a sci class but i have never taken a physics class in my life so i knew that this class was supposed to help me out.</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"I decided to take this because I want to be able to pass my physics class so I won't get farther behind in completing my major. The reason for wanting to work so hard is because I want to try my best to finish college in 4 years, even though I know that it is pretty much 5 years now. I am also taking this course so I can be able to go to PA school and this class is a requirement for my major which will get me into PA school.\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>on the other hand my fantasy football team is pretty good.</td>\n",
       "      <td>0</td>\n",
       "      <td>['I am here because I need it to move on to my other classes and hopefully in the long run become a successful engineer.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>physics has always interested me because i am someone who is looking at how things work.</td>\n",
       "      <td>0</td>\n",
       "      <td>['In addition, I want to become an engineer someday']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4149</th>\n",
       "      <td>life works in mysterious ways and mannn am i learning a whole lot.</td>\n",
       "      <td>0</td>\n",
       "      <td>['I want to go to medical school']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4150</th>\n",
       "      <td>once i complete that i am a step closer into graduating.</td>\n",
       "      <td>0</td>\n",
       "      <td>['I am here to get a passing grade in order to complete my required units for the mathematical field of my degree. Something ive been wanting to do for a long time and that is go to work and helping animals out as a Veterinarian.']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4151 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                      sentence  \\\n",
       "0                               after working minimum wage part time jobs while in community college, i've learned that there is no way i can do that for the rest of my life.   \n",
       "1                                                                                                              i struggle in day to day life and classes because of the grief.   \n",
       "2     it here to learn new things, meet new people, and to be able to learn the culture and how is the america dream that a lot of people from the different country dream of.   \n",
       "3                                                                                                                          jordaan render phys 102 reflection 1 why am i here?   \n",
       "4                                                                                                               i am the first in my family to attempt to get into med school.   \n",
       "...                                                                                                                                                                        ...   \n",
       "4146                   i was not sure if i wanted to take a sci class but i have never taken a physics class in my life so i knew that this class was supposed to help me out.   \n",
       "4147                                                                                                                on the other hand my fantasy football team is pretty good.   \n",
       "4148                                                                                  physics has always interested me because i am someone who is looking at how things work.   \n",
       "4149                                                                                                        life works in mysterious ways and mannn am i learning a whole lot.   \n",
       "4150                                                                                                                  once i complete that i am a step closer into graduating.   \n",
       "\n",
       "      label  \\\n",
       "0         0   \n",
       "1         0   \n",
       "2         0   \n",
       "3         0   \n",
       "4         0   \n",
       "...     ...   \n",
       "4146      0   \n",
       "4147      0   \n",
       "4148      0   \n",
       "4149      0   \n",
       "4150      0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        phrase  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                  ['The bigger reason for why I am here as SF State is to get my degree to get a hopefully get a decent to well paying job when I graduate.']  \n",
       "1                                                                                                                                                                                                        ['To be quite honest, this class is necessary for my degree and most likely to get into medical school. Its a shallow answer, but if I had to elaborate then I would say that this class is a step towards becoming a doctor. Ive wanted to become a doctor for as long as medical books have existed in libraries.']  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                               ['I am here to pursue my career of becoming an Electrical Engineering, and physics is one of the most important parts of it.']  \n",
       "3     ['I am here because I want to receive a quality education around a new group of people and further my academic career as well as personal character development. I would like to use my background in a way that allows me to me travel and connect with many different people from differing cultures and really gain a broader view on life. My current path is to become a Physical Therapist because I enjoy communicating with and helping people and as a PT, I will have many opportunities to travel for work.']  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                  ['I am here because of my goal in trying to get a B.S. in biology concentrated physiology.', 'Im here to become a doctor.']  \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ...  \n",
       "4146                                                                          [\"I decided to take this because I want to be able to pass my physics class so I won't get farther behind in completing my major. The reason for wanting to work so hard is because I want to try my best to finish college in 4 years, even though I know that it is pretty much 5 years now. I am also taking this course so I can be able to go to PA school and this class is a requirement for my major which will get me into PA school.\"]  \n",
       "4147                                                                                                                                                                                                                                                                                                                                                                                                ['I am here because I need it to move on to my other classes and hopefully in the long run become a successful engineer.']  \n",
       "4148                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ['In addition, I want to become an engineer someday']  \n",
       "4149                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ['I want to go to medical school']  \n",
       "4150                                                                                                                                                                                                                                                                                   ['I am here to get a passing grade in order to complete my required units for the mathematical field of my degree. Something ive been wanting to do for a long time and that is go to work and helping animals out as a Veterinarian.']  \n",
       "\n",
       "[4151 rows x 3 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "label\n",
      "0    3856\n",
      "1     846\n",
      "Name: count, dtype: int64\n",
      "Minority samples: 846, Target majority count: 1973, Available majority samples: 3856\n",
      "New class distribution:\n",
      "label\n",
      "0    1973\n",
      "1     846\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming `training_df` already exists and has a 'label' column\n",
    "\n",
    "# Check original class distribution\n",
    "print(\"Original class distribution:\")\n",
    "print(training_df['label'].value_counts())\n",
    "\n",
    "# Set target distribution\n",
    "target_minority_ratio = 0.18\n",
    "\n",
    "  # 20%\n",
    "target_majority_ratio = 0.85  # 80%\n",
    "\n",
    "# Separate majority and minority classes\n",
    "minority_class = training_df[training_df['label'] == 1]\n",
    "majority_class = training_df[training_df['label'] == 0]\n",
    "\n",
    "# Use all samples from the minority class\n",
    "target_minority_count = len(minority_class)\n",
    "\n",
    "# Calculate the maximum possible number of samples for the majority class\n",
    "target_majority_count = min(len(majority_class), int(target_minority_count / target_minority_ratio * target_majority_ratio))\n",
    "\n",
    "# Debug information\n",
    "print(f\"Minority samples: {target_minority_count}, \"\n",
    "      f\"Target majority count: {target_majority_count}, \"\n",
    "      f\"Available majority samples: {len(majority_class)}\")\n",
    "\n",
    "# Perform undersampling\n",
    "if target_majority_count < len(majority_class):\n",
    "    undersampled_majority = resample(\n",
    "        majority_class,\n",
    "        replace=False,  # without replacement\n",
    "        n_samples=target_majority_count,\n",
    "        random_state=42\n",
    "    )\n",
    "else:\n",
    "    print(\"Target majority count exceeds available samples. Using all majority samples.\")\n",
    "    undersampled_majority = majority_class\n",
    "\n",
    "# Combine the resampled majority class with the full minority class\n",
    "training_df = pd.concat([minority_class, undersampled_majority]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check new class distribution\n",
    "print(\"New class distribution:\")\n",
    "print(training_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minority samples: 295, Target minority count: 846, Available majority samples: 3856\n",
      "New class distribution:\n",
      "label\n",
      "0    3856\n",
      "1     846\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Assuming `training_df` is your dataset\n",
    "training_df = oversample_minority(\n",
    "    training_df=training_df,\n",
    "    minority_label=1,  # The label of the minority class\n",
    "    majority_label=0,  # The label of the majority class\n",
    "    target_minority_ratio=0.18  # Target ratio for the minority class\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (4702, 3) \n",
      "Test dataset shape: (462, 3)\n",
      "Positive labels present in the dataset : 846  out of 4702 or 17.99234368353892%\n",
      "Positive labels present in the test dataset : 33  out of 462 or 7.142857142857142%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training dataset shape: {training_df.shape} \\nTest dataset shape: {test_df.shape}\")\n",
    "pos_labels = len([n for n in training_df['label'] if n==1])\n",
    "print(\"Positive labels present in the dataset : {}  out of {} or {}%\".format(pos_labels, len(training_df['label']), (pos_labels/len(training_df['label']))*100))\n",
    "pos_labels = len([n for n in test_df['label'] if n==1])\n",
    "print(\"Positive labels present in the test dataset : {}  out of {} or {}%\".format(pos_labels, len(test_df['label']), (pos_labels/len(test_df['label']))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4702, 3)\n",
      "(462, 3)\n"
     ]
    }
   ],
   "source": [
    "print(training_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Experimental Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(471,)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 21\n",
      "\t95percentile : 41\n",
      "\t99percentile : 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 22\n",
      "\t95percentile : 42\n",
      "\t99percentile : 60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAXLEN = 150\n",
    "\n",
    "X = training_df['sentence']\n",
    "y = training_df['label']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 18, stratify=y)\n",
    "X_test.shape\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "distillbert_transformer = text.Transformer(model_name, maxlen=MAXLEN, class_names=[0,1])\n",
    "training_set = distillbert_transformer.preprocess_train(X_train.tolist(), y_train.tolist())\n",
    "validation_set = distillbert_transformer.preprocess_test(X_test.tolist(), y_test.tolist())\n",
    "distillbert_base_model = distillbert_transformer.get_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60969917 2.77895981]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Define classes and class labels\n",
    "classes = np.array([0, 1])\n",
    "class_labels = list(training_df.label)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=class_labels)\n",
    "\n",
    "# Print class weights\n",
    "print(class_weights)\n",
    "\n",
    "class_weights = dict(zip(classes, class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduce_on_plateau automatically enabled at patience=2\n",
      "\n",
      "\n",
      "begin training using triangular learning rate policy with max lr of 1.2e-05...\n",
      "Epoch 1/1024\n",
      "265/265 [==============================] - 213s 721ms/step - loss: 0.4757 - accuracy: 0.7563 - val_loss: 0.3866 - val_accuracy: 0.8408\n",
      "Epoch 2/1024\n",
      "265/265 [==============================] - 184s 690ms/step - loss: 0.2524 - accuracy: 0.8792 - val_loss: 0.2871 - val_accuracy: 0.8641\n",
      "Epoch 3/1024\n",
      "265/265 [==============================] - 180s 680ms/step - loss: 0.1814 - accuracy: 0.9140 - val_loss: 0.2937 - val_accuracy: 0.8811\n",
      "Epoch 4/1024\n",
      "265/265 [==============================] - 180s 676ms/step - loss: 0.1481 - accuracy: 0.9300 - val_loss: 0.1796 - val_accuracy: 0.9151\n",
      "Epoch 5/1024\n",
      "265/265 [==============================] - 177s 665ms/step - loss: 0.1042 - accuracy: 0.9523 - val_loss: 0.2174 - val_accuracy: 0.9108\n",
      "Epoch 6/1024\n",
      "265/265 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.9598\n",
      "Epoch 00006: Reducing Max LR on Plateau: new max lr will be 6e-06 (if not early_stopping).\n",
      "265/265 [==============================] - 178s 670ms/step - loss: 0.0917 - accuracy: 0.9598 - val_loss: 0.1944 - val_accuracy: 0.9257\n",
      "Epoch 7/1024\n",
      "265/265 [==============================] - 178s 672ms/step - loss: 0.0558 - accuracy: 0.9752 - val_loss: 0.2128 - val_accuracy: 0.9321\n",
      "Epoch 8/1024\n",
      "265/265 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 0.9785\n",
      "Epoch 00008: Reducing Max LR on Plateau: new max lr will be 3e-06 (if not early_stopping).\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "265/265 [==============================] - 177s 668ms/step - loss: 0.0484 - accuracy: 0.9785 - val_loss: 0.1894 - val_accuracy: 0.9321\n",
      "Epoch 8: early stopping\n",
      "Weights from best epoch have been loaded into model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x4477a3280>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build BERT model\n",
    "# model = text.text_classifier('distilbert', train_data=(X_train, y_train), preproc=distillbert_transformer)\n",
    "distillbert_learner = ktrain.get_learner(distillbert_base_model, train_data=training_set, val_data=validation_set, batch_size=16)\n",
    "# learner.fit_onecycle(2e-5, 4, class_weight=class_weights)\n",
    "# learner.autofit(2.27E-06, early_stopping=4)\n",
    "# distillbert_learner.set_weight_decay(0.001)\n",
    "distillbert_learner.autofit(0.000012, early_stopping=4, class_weight=class_weights)\n",
    "# distillbert_learner.set_weight_decay(0.001)\n",
    "# distillbert_learner.autofit(2.27E-06, early_stopping=4, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 18s 647ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.95       386\n",
      "           1       0.69      0.96      0.80        85\n",
      "\n",
      "    accuracy                           0.92       471\n",
      "   macro avg       0.84      0.93      0.87       471\n",
      "weighted avg       0.94      0.92      0.92       471\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[349,  37],\n",
       "       [  3,  82]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distillbert_learner.validate(class_names=distillbert_transformer.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_303 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109483778 (417.65 MB)\n",
      "Trainable params: 109483778 (417.65 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "distillbert_learner.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillbert_predictor = ktrain.get_predictor(distillbert_learner.model, preproc=distillbert_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillbert_test_data = test_df['sentence'].tolist()\n",
    "distillbert_test_label = test_df['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_distillbert = distillbert_predictor.predict(distillbert_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_distillbert = [int(x) for x in y_pred_distillbert]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative: 391, False Positive: 38, False Negative: 11, True Positive: 22\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(distillbert_test_label, y_pred_distillbert).ravel()\n",
    "print('True Negative: {}, False Positive: {}, False Negative: {}, True Positive: {}'.format(tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       429\n",
      "           1       0.37      0.67      0.47        33\n",
      "\n",
      "    accuracy                           0.89       462\n",
      "   macro avg       0.67      0.79      0.71       462\n",
      "weighted avg       0.93      0.89      0.91       462\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('  Classification Report:\\n',classification_report(distillbert_test_label,y_pred_distillbert),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distillbert_predictor.save('../../model/first_generation_distilbert_base_uncased_model_10102020') # 256 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC roc score for distillbert model:  0.6427102188579892\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC roc score for distillbert model: \", roc_auc_score(distillbert_test_label,y_pred_distillbert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
