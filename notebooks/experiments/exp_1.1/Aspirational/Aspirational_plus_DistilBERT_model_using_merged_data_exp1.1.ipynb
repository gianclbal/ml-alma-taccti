{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "seed = 18\n",
    "\n",
    "merged_aspirational_df = pd.read_csv(\"../../../../data/processed_for_model/merged_themes_using_jaccard_method/merged_Aspirational_sentence_level_batch_1_jaccard.csv\", encoding='utf-8')\n",
    "\n",
    "# Shuffle the merged dataset\n",
    "merged_aspirational_df = shuffle(merged_aspirational_df, random_state=seed)\n",
    "\n",
    "# Train-test split \n",
    "training_df, test_df = train_test_split(merged_aspirational_df, test_size=0.2, random_state=18, stratify=merged_aspirational_df['label'])\n",
    "\n",
    "training_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (3763, 3) \n",
      "Test dataset shape: (941, 3)\n",
      "Positive labels present in the dataset : 470  out of 3763 or 12.490034546904067%\n",
      "Positive labels present in the test dataset : 118  out of 941 or 12.539851222104145%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training dataset shape: {training_df.shape} \\nTest dataset shape: {test_df.shape}\")\n",
    "pos_labels = len([n for n in training_df['label'] if n==1])\n",
    "print(\"Positive labels present in the dataset : {}  out of {} or {}%\".format(pos_labels, len(training_df['label']), (pos_labels/len(training_df['label']))*100))\n",
    "pos_labels = len([n for n in test_df['label'] if n==1])\n",
    "print(\"Positive labels present in the test dataset : {}  out of {} or {}%\".format(pos_labels, len(test_df['label']), (pos_labels/len(test_df['label']))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this year has been extremely long and challeng...</td>\n",
       "      <td>0</td>\n",
       "      <td>['So, im here to complete school and walk acro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am here at sfsu to gain the knowledge and ex...</td>\n",
       "      <td>1</td>\n",
       "      <td>['I am here at SFSU to gain the knowledge and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i am taking this sci 115 course so it can help...</td>\n",
       "      <td>0</td>\n",
       "      <td>['Chem 115 is a requirement for me because I a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i have never left the country too which i hate...</td>\n",
       "      <td>0</td>\n",
       "      <td>['I am here because the only thing i want fo b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>with that in mind, i am taking this course so ...</td>\n",
       "      <td>0</td>\n",
       "      <td>['planning on declaring a concentration in zoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>i want to be able to help my family out with p...</td>\n",
       "      <td>0</td>\n",
       "      <td>['I want to get a job in the film industry. Im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3759</th>\n",
       "      <td>i hope to graduate with my degree and run for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>['I am here because I want to be as educated a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3760</th>\n",
       "      <td>i am here to learn about physics that are rela...</td>\n",
       "      <td>1</td>\n",
       "      <td>['I am here to learn about physics that are re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>im here to be a better student and a better ve...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"I'm here to be a better student and a better...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3762</th>\n",
       "      <td>i need to complete one year of physics in orde...</td>\n",
       "      <td>0</td>\n",
       "      <td>['I want to get my bachelors in Child and Adol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3763 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label  \\\n",
       "0     this year has been extremely long and challeng...      0   \n",
       "1     i am here at sfsu to gain the knowledge and ex...      1   \n",
       "2     i am taking this sci 115 course so it can help...      0   \n",
       "3     i have never left the country too which i hate...      0   \n",
       "4     with that in mind, i am taking this course so ...      0   \n",
       "...                                                 ...    ...   \n",
       "3758  i want to be able to help my family out with p...      0   \n",
       "3759  i hope to graduate with my degree and run for ...      0   \n",
       "3760  i am here to learn about physics that are rela...      1   \n",
       "3761  im here to be a better student and a better ve...      1   \n",
       "3762  i need to complete one year of physics in orde...      0   \n",
       "\n",
       "                                                 phrase  \n",
       "0     ['So, im here to complete school and walk acro...  \n",
       "1     ['I am here at SFSU to gain the knowledge and ...  \n",
       "2     ['Chem 115 is a requirement for me because I a...  \n",
       "3     ['I am here because the only thing i want fo b...  \n",
       "4     ['planning on declaring a concentration in zoo...  \n",
       "...                                                 ...  \n",
       "3758  ['I want to get a job in the film industry. Im...  \n",
       "3759  ['I am here because I want to be as educated a...  \n",
       "3760  ['I am here to learn about physics that are re...  \n",
       "3761  [\"I'm here to be a better student and a better...  \n",
       "3762  ['I want to get my bachelors in Child and Adol...  \n",
       "\n",
       "[3763 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_df['sentence']\n",
    "y = training_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 20\n",
      "\t95percentile : 39\n",
      "\t99percentile : 55\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 21\n",
      "\t95percentile : 39\n",
      "\t99percentile : 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ktrain\n",
    "from ktrain import text\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 18, stratify=y)\n",
    "\n",
    "model_name = 'bert-base-cased'\n",
    "\n",
    "distillbert_transformer = text.Transformer(model_name, maxlen=MAXLEN, class_names=[0,1])\n",
    "training_set = distillbert_transformer.preprocess_train(X_train.tolist(), y_train.tolist())\n",
    "validation_set = distillbert_transformer.preprocess_test(X_test.tolist(), y_test.tolist())\n",
    "distillbert_base_model = distillbert_transformer.get_classifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5713635  4.00319149]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Define classes and class labels\n",
    "classes = np.array([0, 1])\n",
    "class_labels = list(training_df.label)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=class_labels)\n",
    "\n",
    "# Print class weights\n",
    "print(class_weights)\n",
    "\n",
    "class_weights = {0:0.5713635,1:4.00319149}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "def reset_random_seeds(seed=2):\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduce_on_plateau automatically enabled at patience=2\n",
      "\n",
      "\n",
      "begin training using triangular learning rate policy with max lr of 2.27e-06...\n",
      "Epoch 1/1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gbaldonado/miniforge3/envs/ml_env/lib/python3.8/site-packages/ktrain/core.py:415: UserWarning: recompiling model to use AdamWeightDecay as opimizer with weight decay of 0.0001\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502/502 [==============================] - 265s 462ms/step - loss: 0.6835 - accuracy: 0.3711 - val_loss: 0.7040 - val_accuracy: 0.5086\n",
      "Epoch 2/1024\n",
      "502/502 [==============================] - 211s 420ms/step - loss: 0.6105 - accuracy: 0.6545 - val_loss: 0.5932 - val_accuracy: 0.7025\n",
      "Epoch 3/1024\n",
      "502/502 [==============================] - 227s 451ms/step - loss: 0.5202 - accuracy: 0.7219 - val_loss: 0.5603 - val_accuracy: 0.6999\n",
      "Epoch 4/1024\n",
      "502/502 [==============================] - 297s 588ms/step - loss: 0.4617 - accuracy: 0.7542 - val_loss: 0.5053 - val_accuracy: 0.7437\n",
      "Epoch 5/1024\n",
      "502/502 [==============================] - 391s 778ms/step - loss: 0.4149 - accuracy: 0.7834 - val_loss: 0.5052 - val_accuracy: 0.7437\n",
      "Epoch 6/1024\n",
      "502/502 [==============================] - 393s 781ms/step - loss: 0.3798 - accuracy: 0.8013 - val_loss: 0.4634 - val_accuracy: 0.7782\n",
      "Epoch 7/1024\n",
      "502/502 [==============================] - 286s 564ms/step - loss: 0.3428 - accuracy: 0.8349 - val_loss: 0.4772 - val_accuracy: 0.7769\n",
      "Epoch 8/1024\n",
      "502/502 [==============================] - ETA: 0s - loss: 0.2990 - accuracy: 0.8605\n",
      "Epoch 00008: Reducing Max LR on Plateau: new max lr will be 1.135e-06 (if not early_stopping).\n",
      "502/502 [==============================] - 292s 580ms/step - loss: 0.2990 - accuracy: 0.8605 - val_loss: 0.5244 - val_accuracy: 0.7703\n",
      "Epoch 9/1024\n",
      "502/502 [==============================] - 274s 544ms/step - loss: 0.2834 - accuracy: 0.8621 - val_loss: 0.4686 - val_accuracy: 0.7968\n",
      "Epoch 10/1024\n",
      "502/502 [==============================] - ETA: 0s - loss: 0.2642 - accuracy: 0.8814\n",
      "Epoch 00010: Reducing Max LR on Plateau: new max lr will be 5.675e-07 (if not early_stopping).\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "502/502 [==============================] - 259s 514ms/step - loss: 0.2642 - accuracy: 0.8814 - val_loss: 0.4699 - val_accuracy: 0.8035\n",
      "Epoch 10: early stopping\n",
      "Weights from best epoch have been loaded into model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x700c4abb0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build BERT model\n",
    "# model = text.text_classifier('distilbert', train_data=(X_train, y_train), preproc=distillbert_transformer)\n",
    "learner = ktrain.get_learner(distillbert_base_model, train_data=training_set, val_data=validation_set, batch_size=6)\n",
    "# learner.fit_onecycle(2e-5, 4, class_weight=class_weights)\n",
    "# learner.autofit(2.27E-06, early_stopping=4)\n",
    "learner.set_weight_decay(0.0001)\n",
    "learner.autofit(2.27E-06, early_stopping=4, class_weight=class_weights)\n",
    "\n",
    "# distillbert_learner.autofit(2.27E-06, early_stopping=4, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 36s 989ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.78      0.86       659\n",
      "           1       0.34      0.80      0.47        94\n",
      "\n",
      "    accuracy                           0.78       753\n",
      "   macro avg       0.65      0.79      0.67       753\n",
      "weighted avg       0.89      0.78      0.81       753\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[511, 148],\n",
       "       [ 19,  75]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.validate(class_names=distillbert_transformer.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative: 611, False Positive: 212, False Negative: 24, True Positive: 94\n",
      "  Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.74      0.84       823\n",
      "           1       0.31      0.80      0.44       118\n",
      "\n",
      "    accuracy                           0.75       941\n",
      "   macro avg       0.63      0.77      0.64       941\n",
      "weighted avg       0.88      0.75      0.79       941\n",
      " \n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "distillbert_predictor = ktrain.get_predictor(learner.model, preproc=distillbert_transformer)\n",
    "\n",
    "distillbert_test_data = test_df['sentence'].tolist()\n",
    "distillbert_test_label = test_df['label'].tolist()\n",
    "\n",
    "y_pred_distillbert = distillbert_predictor.predict(distillbert_test_data)\n",
    "\n",
    "y_pred_distillbert = [int(x) for x in y_pred_distillbert]\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(distillbert_test_label, y_pred_distillbert).ravel()\n",
    "print('True Negative: {}, False Positive: {}, False Negative: {}, True Positive: {}'.format(tn, fp, fn, tp))\n",
    "\n",
    "print('  Classification Report:\\n',classification_report(distillbert_test_label,y_pred_distillbert),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Negative: 681, False Positive: 142, False Negative: 40, True Positive: 78\n",
    "  Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.94      0.83      0.88       823\n",
    "           1       0.35      0.66      0.46       118\n",
    "\n",
    "    accuracy                           0.81       941\n",
    "   macro avg       0.65      0.74      0.67       941\n",
    "weighted avg       0.87      0.81      0.83       941"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillbert_predictor.save('../../../../saved_models/aspirational_bert_base_cased_model_08012024_v1') # 0.67 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 29s 427ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.95      0.97      1440\n",
      "    positive       0.71      0.88      0.78       185\n",
      "\n",
      "    accuracy                           0.94      1625\n",
      "   macro avg       0.85      0.91      0.88      1625\n",
      "weighted avg       0.95      0.94      0.95      1625\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1373,   67],\n",
       "       [  23,  162]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.validate(class_names=distillbert_transformer.get_classes())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
