{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "seed = 18\n",
    "\n",
    "merged_aspirational_df = pd.read_csv(\"/Users/gbaldonado/Developer/ml-alma-taccti/ml-alma-taccti/data/processed_for_model/merged_themes_using_jaccard_method/merged_Aspirational_sentence_level_batch_1_jaccard.csv\", encoding='utf-8')\n",
    "\n",
    "# Shuffle the merged dataset\n",
    "merged_aspirational_df = shuffle(merged_aspirational_df, random_state=seed)\n",
    "\n",
    "# Train-test split \n",
    "training_df, test_df = train_test_split(merged_aspirational_df, test_size=0.1, random_state=18, stratify=merged_aspirational_df['label'])\n",
    "\n",
    "training_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_df['sentence']\n",
    "y = training_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 21\n",
      "\t95percentile : 40\n",
      "\t99percentile : 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 20\n",
      "\t95percentile : 37\n",
      "\t99percentile : 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ktrain\n",
    "from ktrain import text\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 18, stratify=y)\n",
    "\n",
    "model_name = 'bert-base-cased'\n",
    "\n",
    "distillbert_transformer = text.Transformer(model_name, maxlen=MAXLEN, class_names=[0,1])\n",
    "training_set = distillbert_transformer.preprocess_train(X_train.tolist(), y_train.tolist())\n",
    "validation_set = distillbert_transformer.preprocess_test(X_test.tolist(), y_test.tolist())\n",
    "distillbert_base_model = distillbert_transformer.get_classifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57152778 3.99514563]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Define classes and class labels\n",
    "classes = np.array([0, 1])\n",
    "class_labels = list(training_df.label)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=class_labels)\n",
    "\n",
    "# Print class weights\n",
    "print(class_weights)\n",
    "\n",
    "class_weights = {0:0.56103896,1:4.59574468}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "def reset_random_seeds(seed=2):\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduce_on_plateau automatically enabled at patience=2\n",
      "\n",
      "\n",
      "begin training using triangular learning rate policy with max lr of 2e-05...\n",
      "Epoch 1/1024\n",
      "330/330 [==============================] - 177s 464ms/step - loss: 0.3687 - accuracy: 0.8744 - val_loss: 0.3049 - val_accuracy: 0.8747\n",
      "Epoch 2/1024\n",
      "330/330 [==============================] - 117s 352ms/step - loss: 0.2914 - accuracy: 0.8678 - val_loss: 0.3031 - val_accuracy: 0.8717\n",
      "Epoch 3/1024\n",
      "330/330 [==============================] - 118s 354ms/step - loss: 0.2210 - accuracy: 0.8987 - val_loss: 0.3126 - val_accuracy: 0.8497\n",
      "Epoch 4/1024\n",
      "330/330 [==============================] - ETA: 0s - loss: 0.1955 - accuracy: 0.9170\n",
      "Epoch 00004: Reducing Max LR on Plateau: new max lr will be 1e-05 (if not early_stopping).\n",
      "330/330 [==============================] - 117s 353ms/step - loss: 0.1955 - accuracy: 0.9170 - val_loss: 0.3220 - val_accuracy: 0.8390\n",
      "Epoch 5/1024\n",
      "330/330 [==============================] - ETA: 0s - loss: 0.1297 - accuracy: 0.9478Restoring model weights from the end of the best epoch: 2.\n",
      "330/330 [==============================] - 114s 343ms/step - loss: 0.1297 - accuracy: 0.9478 - val_loss: 0.3769 - val_accuracy: 0.8443\n",
      "Epoch 5: early stopping\n",
      "Weights from best epoch have been loaded into model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x5ebec8e50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build BERT model\n",
    "# model = text.text_classifier('distilbert', train_data=(X_train, y_train), preproc=distillbert_transformer)\n",
    "learner = ktrain.get_learner(distillbert_base_model, train_data=training_set, val_data=validation_set, batch_size=6)\n",
    "learner.autofit(2e-5, early_stopping=3)\n",
    "# learner.autofit(2.27E-06, early_stopping=4)\n",
    "# distillbert_learner.autofit(2.27E-06, early_stopping=4, class_weight=class_weights)\n",
    "# distillbert_learner.set_weight_decay(0.001)\n",
    "# distillbert_learner.autofit(2.27E-06, early_stopping=4, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 33s 504ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      1152\n",
      "           1       0.30      0.02      0.03       165\n",
      "\n",
      "    accuracy                           0.87      1317\n",
      "   macro avg       0.59      0.51      0.48      1317\n",
      "weighted avg       0.80      0.87      0.82      1317\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1145,    7],\n",
       "       [ 162,    3]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.validate(class_names=distillbert_transformer.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative: 1225, False Positive: 11, False Negative: 172, True Positive: 4\n",
      "  Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      1236\n",
      "           1       0.27      0.02      0.04       176\n",
      "\n",
      "    accuracy                           0.87      1412\n",
      "   macro avg       0.57      0.51      0.49      1412\n",
      "weighted avg       0.80      0.87      0.82      1412\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "distillbert_predictor = ktrain.get_predictor(learner.model, preproc=distillbert_transformer)\n",
    "\n",
    "distillbert_test_data = test_df['sentence'].tolist()\n",
    "distillbert_test_label = test_df['label'].tolist()\n",
    "\n",
    "y_pred_distillbert = distillbert_predictor.predict(distillbert_test_data)\n",
    "\n",
    "y_pred_distillbert = [int(x) for x in y_pred_distillbert]\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(distillbert_test_label, y_pred_distillbert).ravel()\n",
    "print('True Negative: {}, False Positive: {}, False Negative: {}, True Positive: {}'.format(tn, fp, fn, tp))\n",
    "\n",
    "print('  Classification Report:\\n',classification_report(distillbert_test_label,y_pred_distillbert),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# distillbert_predictor.save('../../../../saved_models/social_bert_base_cased_model_08012024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 29s 427ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.95      0.97      1440\n",
      "    positive       0.71      0.88      0.78       185\n",
      "\n",
      "    accuracy                           0.94      1625\n",
      "   macro avg       0.85      0.91      0.88      1625\n",
      "weighted avg       0.95      0.94      0.95      1625\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1373,   67],\n",
       "       [  23,  162]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.validate(class_names=distillbert_transformer.get_classes())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
