{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "seed = 18\n",
    "\n",
    "merged_resistance_df = pd.read_csv(\"/Users/gbaldonado/Developer/ml-alma-taccti/ml-alma-taccti/data/processed_for_model/essay_level/merged_themes_essay_level/merged_Resistance_essay_level_batch_1.csv\", encoding='utf-8')\n",
    "\n",
    "# Shuffle the merged dataset\n",
    "merged_resistance_df = shuffle(merged_resistance_df, random_state=seed)\n",
    "\n",
    "# Train-test split \n",
    "training_df, test_df = train_test_split(merged_resistance_df, test_size=0.2, random_state=18, stratify=merged_resistance_df['label'])\n",
    "\n",
    "training_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (942, 3) \n",
      "Test dataset shape: (236, 3)\n",
      "Positive labels present in the dataset : 118  out of 942 or 12.526539278131635%\n",
      "Positive labels present in the test dataset : 29  out of 236 or 12.288135593220339%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training dataset shape: {training_df.shape} \\nTest dataset shape: {test_df.shape}\")\n",
    "pos_labels = len([n for n in training_df['label'] if n==1])\n",
    "print(\"Positive labels present in the dataset : {}  out of {} or {}%\".format(pos_labels, len(training_df['label']), (pos_labels/len(training_df['label']))*100))\n",
    "pos_labels = len([n for n in test_df['label'] if n==1])\n",
    "print(\"Positive labels present in the test dataset : {}  out of {} or {}%\".format(pos_labels, len(test_df['label']), (pos_labels/len(test_df['label']))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_df['essay']\n",
    "y = training_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 158\n",
      "\t95percentile : 248\n",
      "\t99percentile : 325\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 155\n",
      "\t95percentile : 253\n",
      "\t99percentile : 322\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ktrain\n",
    "from ktrain import text\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 18, stratify=y)\n",
    "\n",
    "model_name = 'bert-base-cased'\n",
    "\n",
    "distillbert_transformer = text.Transformer(model_name, maxlen=MAXLEN, class_names=[0,1])\n",
    "training_set = distillbert_transformer.preprocess_train(X_train.tolist(), y_train.tolist())\n",
    "validation_set = distillbert_transformer.preprocess_test(X_test.tolist(), y_test.tolist())\n",
    "distillbert_base_model = distillbert_transformer.get_classifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57160194 3.99152542]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Define classes and class labels\n",
    "classes = np.array([0, 1])\n",
    "class_labels = list(training_df.label)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=class_labels)\n",
    "\n",
    "# Print class weights\n",
    "print(class_weights)\n",
    "\n",
    "class_weights = {0:0.56103896,1:4.59574468}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "def reset_random_seeds(seed=2):\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduce_on_plateau automatically enabled at patience=2\n",
      "\n",
      "\n",
      "begin training using triangular learning rate policy with max lr of 2e-05...\n",
      "Epoch 1/1024\n",
      "110/110 [==============================] - 193s 2s/step - loss: 0.7199 - accuracy: 0.6024 - val_loss: 0.5632 - val_accuracy: 0.6961\n",
      "Epoch 2/1024\n",
      "110/110 [==============================] - 149s 1s/step - loss: 0.5510 - accuracy: 0.6646 - val_loss: 0.6261 - val_accuracy: 0.6290\n",
      "Epoch 3/1024\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.4205 - accuracy: 0.7709\n",
      "Epoch 00003: Reducing Max LR on Plateau: new max lr will be 1e-05 (if not early_stopping).\n",
      "110/110 [==============================] - 143s 1s/step - loss: 0.4205 - accuracy: 0.7709 - val_loss: 0.8008 - val_accuracy: 0.6078\n",
      "Epoch 4/1024\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.3257 - accuracy: 0.8376Restoring model weights from the end of the best epoch: 1.\n",
      "110/110 [==============================] - 139s 1s/step - loss: 0.3257 - accuracy: 0.8376 - val_loss: 0.5925 - val_accuracy: 0.7385\n",
      "Epoch 4: early stopping\n",
      "Weights from best epoch have been loaded into model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x30b45ab20>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build BERT model\n",
    "# model = text.text_classifier('distilbert', train_data=(X_train, y_train), preproc=distillbert_transformer)\n",
    "learner = ktrain.get_learner(distillbert_base_model, train_data=training_set, val_data=validation_set, batch_size=6)\n",
    "learner.autofit(2e-5, class_weight=class_weights, early_stopping=3)\n",
    "# learner.autofit(2.27E-06, early_stopping=4)\n",
    "# distillbert_learner.autofit(2.27E-06, early_stopping=4, class_weight=class_weights)\n",
    "# distillbert_learner.set_weight_decay(0.001)\n",
    "# distillbert_learner.autofit(2.27E-06, early_stopping=4, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 12s 1s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.73      0.81       248\n",
      "           1       0.19      0.43      0.26        35\n",
      "\n",
      "    accuracy                           0.70       283\n",
      "   macro avg       0.54      0.58      0.53       283\n",
      "weighted avg       0.81      0.70      0.74       283\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[182,  66],\n",
       "       [ 20,  15]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.validate(class_names=distillbert_transformer.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative: 145, False Positive: 62, False Negative: 15, True Positive: 14\n",
      "  Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.70      0.79       207\n",
      "           1       0.18      0.48      0.27        29\n",
      "\n",
      "    accuracy                           0.67       236\n",
      "   macro avg       0.55      0.59      0.53       236\n",
      "weighted avg       0.82      0.67      0.73       236\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "distillbert_predictor = ktrain.get_predictor(learner.model, preproc=distillbert_transformer)\n",
    "\n",
    "distillbert_test_data = test_df['essay'].tolist()\n",
    "distillbert_test_label = test_df['label'].tolist()\n",
    "\n",
    "y_pred_distillbert = distillbert_predictor.predict(distillbert_test_data)\n",
    "\n",
    "y_pred_distillbert = [int(x) for x in y_pred_distillbert]\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(distillbert_test_label, y_pred_distillbert).ravel()\n",
    "print('True Negative: {}, False Positive: {}, False Negative: {}, True Positive: {}'.format(tn, fp, fn, tp))\n",
    "\n",
    "print('  Classification Report:\\n',classification_report(distillbert_test_label,y_pred_distillbert),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "distillbert_predictor.save('../../../../saved_models/social_bert_base_cased_model_08012024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 29s 427ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.95      0.97      1440\n",
      "    positive       0.71      0.88      0.78       185\n",
      "\n",
      "    accuracy                           0.94      1625\n",
      "   macro avg       0.85      0.91      0.88      1625\n",
      "weighted avg       0.95      0.94      0.95      1625\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1373,   67],\n",
       "       [  23,  162]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.validate(class_names=distillbert_transformer.get_classes())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
