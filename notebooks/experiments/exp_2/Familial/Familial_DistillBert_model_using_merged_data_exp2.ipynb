{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Familial DistilBERT Model Using Merged Data Batch 1 + Batch 2 Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ktrain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from ktrain import text\n",
    "import random\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import warnings\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Set random seed\n",
    "random.seed(18)\n",
    "seed = 18\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the data and quick exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_familial_df_batch_1 = pd.read_csv(\"/Users/gbaldonado/Developer/ml-alma-taccti/ml-alma-taccti/data/processed_for_model/merged_themes_using_jaccard_method/merged_Familial_sentence_level_batch_1_jaccard.csv\", encoding='utf-8')\n",
    "merged_familial_df_batch_2 = pd.read_csv(\"/Users/gbaldonado/Developer/ml-alma-taccti/ml-alma-taccti/data/processed_for_model/merged_themes_using_jaccard_method/Familial Plus_sentence_level_batch_2_jaccard.csv\", encoding='utf-8')\n",
    "\n",
    "merged_familial_df = pd.concat([merged_familial_df_batch_1, merged_familial_df_batch_2])\n",
    "\n",
    "# Shuffle the merged dataset\n",
    "merged_familial_df = shuffle(merged_familial_df, random_state=seed)\n",
    "\n",
    "# Train-test split \n",
    "training_df, test_df = train_test_split(merged_familial_df, test_size=0.1, random_state=42, stratify=merged_familial_df['label'])\n",
    "\n",
    "training_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (2380, 3) \n",
      "Test dataset shape: (265, 3)\n",
      "Positive labels present in the dataset : 228  out of 2380 or 9.57983193277311%\n",
      "Positive labels present in the test dataset : 25  out of 265 or 9.433962264150944%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training dataset shape: {training_df.shape} \\nTest dataset shape: {test_df.shape}\")\n",
    "pos_labels = len([n for n in training_df['label'] if n==1])\n",
    "print(\"Positive labels present in the dataset : {}  out of {} or {}%\".format(pos_labels, len(training_df['label']), (pos_labels/len(training_df['label']))*100))\n",
    "pos_labels = len([n for n in test_df['label'] if n==1])\n",
    "print(\"Positive labels present in the test dataset : {}  out of {} or {}%\".format(pos_labels, len(test_df['label']), (pos_labels/len(test_df['label']))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2380, 3)\n",
      "(265, 3)\n"
     ]
    }
   ],
   "source": [
    "print(training_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Experimental Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_df['sentence']\n",
    "y = training_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 18, stratify=y)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = np.inf  # Initialize with a very large value for minimum loss\n",
    "best_val_acc = 0  # Initialize with a very low accuracy\n",
    "best_model = None  # Placeholder to store the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55297398 5.21929825]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0.5529739776951673, 1: 5.219298245614035}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "# Define classes and class labels\n",
    "classes = np.array([0, 1])\n",
    "class_labels = list(training_df.label)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=class_labels)\n",
    "\n",
    "# Print class weights\n",
    "print(class_weights)\n",
    "\n",
    "dict(zip(classes, class_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Metal device set to: Apple M2 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 21\n",
      "\t95percentile : 42\n",
      "\t99percentile : 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 21\n",
      "\t95percentile : 40\n",
      "\t99percentile : 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using triangular learning rate policy with max lr of 2e-05...\n",
      "Epoch 1/2\n",
      "318/318 [==============================] - 68s 190ms/step - loss: 0.4951 - accuracy: 0.7994 - val_loss: 0.3974 - val_accuracy: 0.8319\n",
      "Epoch 2/2\n",
      "318/318 [==============================] - 56s 174ms/step - loss: 0.3123 - accuracy: 0.8367 - val_loss: 0.3721 - val_accuracy: 0.8256\n",
      "15/15 [==============================] - 5s 258ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.81      0.89       431\n",
      "           1       0.35      0.98      0.51        45\n",
      "\n",
      "    accuracy                           0.83       476\n",
      "   macro avg       0.67      0.89      0.70       476\n",
      "weighted avg       0.94      0.83      0.86       476\n",
      "\n",
      "Fold 1 - Validation Accuracy: 0.8256, Validation Loss: 0.3721\n",
      "Fold 2/5\n",
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 21\n",
      "\t95percentile : 41\n",
      "\t99percentile : 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 22\n",
      "\t95percentile : 44\n",
      "\t99percentile : 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using triangular learning rate policy with max lr of 2e-05...\n",
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "# Number of folds for cross-validation\n",
    "n_folds = 5\n",
    "MAXLEN = 150\n",
    "model_name = 'distilbert-base-uncased'\n",
    "\n",
    "# Initialize stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=n_folds)\n",
    "\n",
    "# Placeholder for results\n",
    "cv_results = []\n",
    "\n",
    "# Loop over each fold\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Fold {fold + 1}/{n_folds}\")\n",
    "\n",
    "    # Split the data into training and validation sets using .iloc\n",
    "    X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Convert to list format (if they are pandas Series)\n",
    "    X_train_fold = X_train_fold.tolist()\n",
    "    X_val_fold = X_val_fold.tolist()\n",
    "    y_train_fold = y_train_fold.tolist()\n",
    "    y_val_fold = y_val_fold.tolist()\n",
    "\n",
    "    # Define classes and class labels\n",
    "    classes = np.array([0, 1])\n",
    "    class_labels = list(training_df.label)\n",
    "\n",
    "    # Compute class weights\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=class_labels)\n",
    "\n",
    "\n",
    "    # Initialize the distillbert transformer for this fold\n",
    "    distillbert_transformer = text.Transformer(model_name, maxlen=MAXLEN, class_names=[0, 1])\n",
    "\n",
    "    # Preprocess the training and validation sets for the current fold\n",
    "    training_set = distillbert_transformer.preprocess_train(X_train_fold, y_train_fold)\n",
    "    validation_set = distillbert_transformer.preprocess_test(X_val_fold, y_val_fold)\n",
    "\n",
    "    # Build the model\n",
    "    distillbert_base_model = distillbert_transformer.get_classifier()\n",
    "\n",
    "    # Initialize the learner\n",
    "    distilbert_learner = ktrain.get_learner(\n",
    "        distillbert_base_model, train_data=training_set, val_data=validation_set, batch_size=6\n",
    "    )\n",
    "\n",
    "    # Apply weight decay\n",
    "    distilbert_learner.set_weight_decay(0.001)\n",
    "\n",
    "    # Train the model with autofit and early stopping\n",
    "    distilbert_learner.autofit(2e-5, 2, class_weight=dict(zip(classes, class_weights)))\n",
    "\n",
    "    distilbert_learner.validate(class_names=distillbert_transformer.get_classes())\n",
    "\n",
    "\n",
    "    # Access the validation loss and accuracy from the last epoch\n",
    "    val_loss = distilbert_learner.history.history['val_loss'][-1]\n",
    "    val_acc = distilbert_learner.history.history['val_accuracy'][-1]\n",
    "\n",
    "    # Store the result for this fold\n",
    "    print(f\"Fold {fold+1} - Validation Accuracy: {val_acc:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "    cv_results.append((val_loss, val_acc))\n",
    "\n",
    "    \n",
    "\n",
    "    # Update the best model if the current one has a lower validation loss\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_val_acc = val_acc\n",
    "        best_model = distilbert_learner.model  # Save the best model\n",
    "\n",
    "    gc.collect()\n",
    "    del distilbert_learner.model\n",
    "\n",
    "# After all folds are done, compute mean and std of the performance\n",
    "mean_val_acc = np.mean([x[1] for x in cv_results])\n",
    "std_val_acc = np.std([x[1] for x in cv_results])\n",
    "\n",
    "mean_val_loss = np.mean([x[0] for x in cv_results])\n",
    "std_val_loss = np.std([x[0] for x in cv_results])\n",
    "\n",
    "print(f\"Mean Validation Accuracy: {mean_val_acc:.4f} (+/- {std_val_acc:.4f})\")\n",
    "print(f\"Mean Validation Loss: {mean_val_loss:.4f} (+/- {std_val_loss:.4f})\")\n",
    "\n",
    "# Print the best model's validation performance\n",
    "print(f\"Best Model - Validation Accuracy: {best_val_acc:.4f}, Validation Loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 21\n",
      "\t95percentile : 43\n",
      "\t99percentile : 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95       240\n",
      "           1       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.91       265\n",
      "   macro avg       0.45      0.50      0.48       265\n",
      "weighted avg       0.82      0.91      0.86       265\n",
      "\n",
      "Holdout Set - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95       240\n",
      "           1       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.91       265\n",
      "   macro avg       0.45      0.50      0.48       265\n",
      "weighted avg       0.82      0.91      0.86       265\n",
      "\n",
      "True Negative: 240, False Positive: 0, False Negative: 25, True Positive: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Get current time\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Create 'performance' folder if it doesn't exist\n",
    "if not os.path.exists('performance'):\n",
    "    os.makedirs('performance')\n",
    "\n",
    "# Evaluate the best model on the holdout set\n",
    "distillbert_test_data = test_df['sentence'].tolist()\n",
    "distillbert_test_label = test_df['label'].tolist()\n",
    "\n",
    "# Preprocess the holdout data\n",
    "holdout_set = distillbert_transformer.preprocess_test(distillbert_test_data, distillbert_test_label)\n",
    "\n",
    "# Create a new learner for the best model and evaluate it on the holdout set\n",
    "best_predictor = ktrain.get_predictor(best_model, preproc=distillbert_transformer)\n",
    "\n",
    "\n",
    "# Print the confusion matrix and classification report for the best model on the holdout set\n",
    "y_pred_distillbert = best_predictor.predict(distillbert_test_data)\n",
    "y_pred_distillbert = [int(x) for x in y_pred_distillbert]\n",
    "\n",
    "# Classification report and confusion matrix for holdout set\n",
    "holdout_report = classification_report(distillbert_test_label, y_pred_distillbert)\n",
    "print(holdout_report)\n",
    "tn, fp, fn, tp = confusion_matrix(distillbert_test_label, y_pred_distillbert).ravel()\n",
    "holdout_matrix = 'True Negative: {}, False Positive: {}, False Negative: {}, True Positive: {}'.format(tn, fp, fn, tp)\n",
    "\n",
    "print(f\"Holdout Set - Classification Report:\\n{holdout_report}\")\n",
    "print(holdout_matrix)\n",
    "\n",
    "# Filename for metrics\n",
    "filename = 'performance/metrics.txt'  # Using a fixed filename to append to\n",
    "\n",
    "# Save classification report and confusion matrix for holdout set\n",
    "# Open file in append mode; it will create the file if it doesn't exist\n",
    "with open(filename, 'a') as f:\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(current_time)\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(\"Holdout Set - Classification Report:\\n\")\n",
    "    f.write(str(holdout_report))\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(\"Holdout Set - Confusion Matrix:\\n\")\n",
    "    f.write(holdout_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55297398 5.21929825]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Define classes and class labels\n",
    "classes = np.array([0, 1])\n",
    "class_labels = list(training_df.label)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=class_labels)\n",
    "\n",
    "# Print class weights\n",
    "print(class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduce_on_plateau automatically enabled at patience=2\n",
      "\n",
      "\n",
      "begin training using triangular learning rate policy with max lr of 2e-05...\n",
      "Epoch 1/1024\n",
      "357/357 [==============================] - 130s 315ms/step - loss: 0.3039 - accuracy: 0.8880 - val_loss: 0.1906 - val_accuracy: 0.9076\n",
      "Epoch 2/1024\n",
      "357/357 [==============================] - 110s 306ms/step - loss: 0.1886 - accuracy: 0.9066 - val_loss: 0.1800 - val_accuracy: 0.9328\n",
      "Epoch 3/1024\n",
      "357/357 [==============================] - 112s 312ms/step - loss: 0.1583 - accuracy: 0.9169 - val_loss: 0.1677 - val_accuracy: 0.9160\n",
      "Epoch 4/1024\n",
      "357/357 [==============================] - 114s 316ms/step - loss: 0.1346 - accuracy: 0.9370 - val_loss: 0.1661 - val_accuracy: 0.9118\n",
      "Epoch 5/1024\n",
      "357/357 [==============================] - 112s 311ms/step - loss: 0.1143 - accuracy: 0.9519 - val_loss: 0.1902 - val_accuracy: 0.9286\n",
      "Epoch 6/1024\n",
      "357/357 [==============================] - 118s 329ms/step - loss: 0.0964 - accuracy: 0.9603 - val_loss: 0.1652 - val_accuracy: 0.9286\n",
      "Epoch 7/1024\n",
      "357/357 [==============================] - 118s 329ms/step - loss: 0.0697 - accuracy: 0.9678 - val_loss: 0.1864 - val_accuracy: 0.9244\n",
      "Epoch 8/1024\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.9678\n",
      "Epoch 00008: Reducing Max LR on Plateau: new max lr will be 1e-05 (if not early_stopping).\n",
      "357/357 [==============================] - 116s 323ms/step - loss: 0.0777 - accuracy: 0.9678 - val_loss: 0.1739 - val_accuracy: 0.9244\n",
      "Epoch 9/1024\n",
      "357/357 [==============================] - 116s 323ms/step - loss: 0.0612 - accuracy: 0.9757 - val_loss: 0.2014 - val_accuracy: 0.9160\n",
      "Epoch 10/1024\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9753\n",
      "Epoch 00010: Reducing Max LR on Plateau: new max lr will be 5e-06 (if not early_stopping).\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "357/357 [==============================] - 117s 325ms/step - loss: 0.0526 - accuracy: 0.9753 - val_loss: 0.1955 - val_accuracy: 0.9286\n",
      "Epoch 10: early stopping\n",
      "Weights from best epoch have been loaded into model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x359ddb7c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build BERT model\n",
    "# model = text.text_classifier('distilbert', train_data=(X_train, y_train), preproc=distillbert_transformer)\n",
    "distillbert_learner = ktrain.get_learner(distillbert_base_model, train_data=training_set, val_data=validation_set, batch_size=6)\n",
    "# learner.fit_onecycle(2e-5, 4, class_weight=class_weights)\n",
    "# learner.autofit(2.27E-06, early_stopping=4)\n",
    "distillbert_learner.set_weight_decay(0.001)\n",
    "distillbert_learner.autofit(2e-5, early_stopping=4)\n",
    "# distillbert_learner.set_weight_decay(0.001)\n",
    "# distillbert_learner.autofit(2.27E-06, early_stopping=4, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 13s 632ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       215\n",
      "           1       0.62      0.70      0.65        23\n",
      "\n",
      "    accuracy                           0.93       238\n",
      "   macro avg       0.79      0.82      0.81       238\n",
      "weighted avg       0.93      0.93      0.93       238\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[205,  10],\n",
       "       [  7,  16]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distillbert_learner.validate(class_names=distillbert_transformer.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109483778 (417.65 MB)\n",
      "Trainable params: 109483778 (417.65 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "distillbert_learner.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillbert_predictor = ktrain.get_predictor(distillbert_learner.model, preproc=distillbert_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillbert_test_data = test_df['sentence'].tolist()\n",
    "distillbert_test_label = test_df['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_distillbert = distillbert_predictor.predict(distillbert_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_distillbert = [int(x) for x in y_pred_distillbert]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative: 229, False Positive: 11, False Negative: 19, True Positive: 6\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(distillbert_test_label, y_pred_distillbert).ravel()\n",
    "print('True Negative: {}, False Positive: {}, False Negative: {}, True Positive: {}'.format(tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94       240\n",
      "           1       0.35      0.24      0.29        25\n",
      "\n",
      "    accuracy                           0.89       265\n",
      "   macro avg       0.64      0.60      0.61       265\n",
      "weighted avg       0.87      0.89      0.88       265\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('  Classification Report:\\n',classification_report(distillbert_test_label,y_pred_distillbert),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distillbert_predictor.save('../../model/first_generation_distilbert_base_uncased_model_10102020') # 256 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC roc score for distillbert model:  0.5970833333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC roc score for distillbert model: \", roc_auc_score(distillbert_test_label,y_pred_distillbert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
